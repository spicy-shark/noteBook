# MQ Redis SPringCloud Mongo mysql 多线程

问的比较多的其实是Java基础、Redis缓存的使用、微服务之间的通信日志追踪等

# 面经

- https://www.nowcoder.com/discuss/701951?type=2&order=0&pos=19&page=0&channel=-1&source_id=discuss_center_2_nctrack
- https://www.jianshu.com/p/6df958612168
- http://www.ekangw.net/a/diannaojiqiao/2022/0803/175140.html
- https://zhuanlan.zhihu.com/p/524314257
- http://www.guoxiaolong.cn/blog/?id=11327
- https://www.bilibili.com/read/cv18491209
- https://www.cnblogs.com/zlnnjit/p/12782653.html
- 

# 简历

* 负责所属模块的代码开发，调试与维护工作；对接WEB端和移动端，编写相关接口设计文档。
* 负责项目的运营管理平台的开发维护与优化任务。
* 负责项目配置中心的维护工作。
* 参与项目架构优化与服务拆分。
* 协助并完成其他的技术任务开发。
* 负责所属模块的代码开发，调试与维护工作；对接WEB端和移动端，编写相关接口设计文档。
* 负责音视频通话模块的运营商对接优化工作。
* 负责项目的运营管理平台的开发维护与优化任务。
* 负责配置中心的维护工作。优化并项目配置项并应用至Apollo配置中心。
* 参与项目架构优化与服务拆分。
* 协助并完成其他的技术任务开发。

# Spring

## Spring、SpringMVC、SpringBoot、SpringCloud的区别

Spring是一个“引擎”；

Spring MVC是基于Spring的一个MVC框架；

Spring Boot是基于Spring框架等一套快速开发整合包；

Spring Cloud是基于Spring Boot搭建的分布式微服务系统解决方案。

Spring MVC 是 Spring 中的一个很重要的模块，主要赋予 Spring 快速构建 MVC 架构的 Web 程序的能力。MVC 是模型(Model)、视图(View)、控制器(Controller)的简写，其核心思想是通过将业务逻辑、数据、显示分离来组织代码。

Spring Boot 只是简化了配置，如果你需要构建 MVC 架构的 Web 程序，你还是需要使用 Spring MVC 作为 MVC 框架，只是说 Spring Boot 帮你简化了 Spring MVC 的很多配置，真正做到开箱即用！

## SpringCloud五大组件

https://worktile.com/kb/ask/22743.html

- Eureka
- Ribbon
- Hystrix
- Zuul
- Config

## Spring IoC

IoC 的思想就是将原本在程序中手动创建对象的控制权，交由 Spring 框架来管理。控制反转就是将对象之间的相互依赖关系交给 IoC 容器来管理，并由 IoC 容器完成对象的注入。这样可以很大程度上简化应用的开发，把应用从复杂的依赖关系中解放出来。

在实际项目中一个 Service 类可能依赖了很多其他的类，假如我们需要实例化这个 Service，你可能要每次都要搞清这个 Service 所有底层类的构造函数，这可能会把人逼疯。如果利用 IoC 的话，你只需要配置好，然后在需要的地方引用就行了，这大大增加了项目的可维护性且降低了开发难度。在 Spring 中， IoC 容器是 Spring 用来实现 IoC 的载体， IoC 容器实际上就是个 Map（key，value），Map 中存放的是各种对象。

我们把IoC容器所管理的对象称为Bean。

## Bean

### 将一个类声明为 Bean 的注解有：

* `@Component` ：通用的注解，可标注任意类为 `Spring` 组件。如果一个 Bean 不知道属于哪个层，可以使用 `@Component` 注解标注。
* `@Repository` : 对应持久层即 Dao 层，主要用于数据库相关操作。
* `@Service` : 对应服务层，主要涉及一些复杂的逻辑，需要用到 Dao 层。
* `@Controller` : 对应 Spring MVC 控制层，主要用户接受用户请求并调用 Service 层返回数据给前端页面。

### @Component 和 @Bean 的区别：

* `@Component` 注解作用于类，而 `@Bean`注解作用于方法。
* `@Component`通常是通过类路径扫描来自动侦测以及自动装配到 Spring 容器中（我们可以使用 `@ComponentScan` 注解定义要扫描的路径从中找出标识了需要装配的类自动装配到 Spring 的 bean 容器中）。`@Bean` 注解通常是我们在标有该注解的方法中定义产生这个 bean,`@Bean`告诉了 Spring 这是某个类的实例，当我需要用它的时候还给我。
* `@Bean` 注解比 `@Component` 注解的自定义性更强，而且很多地方我们只能通过 `@Bean` 注解来注册 bean。比如当我们引用第三方库中的类需要装配到 `Spring`容器时，则只能通过 `@Bean`来实现。

下面这个例子是通过 `@Component` 无法实现的。

```java
@Bean
public OneService getService(status) {
    case (status)  {
        when 1:
                return new serviceImpl1();
        when 2:
                return new serviceImpl2();
        when 3:
                return new serviceImpl3();
    }
}

```

### 注入Bean的注解有哪些

Spring 内置的 `@Autowired` 以及 JDK 内置的 `@Resource` 和 `@Inject` 都可以用于注入 Bean。

| Annotaion      | Package                              | Source       |
| -------------- | ------------------------------------ | ------------ |
| `@Autowired` | `org.springframework.bean.factory` | Spring 2.5+  |
| `@Resource`  | `javax.annotation`                 | Java JSR-250 |
| `@Inject`    | `javax.inject`                     | Java JSR-330 |

`@Autowired` 和 `@Resource`使用的比较多一些。

`@Autowired` 和 `@Resource`的区别：

* `@Autowired` 是 Spring 提供的注解，`@Resource` 是 JDK 提供的注解。
* `Autowired` 默认的注入方式为 `byType`（根据类型进行匹配），`@Resource`默认注入方式为 `byName`（根据名称进行匹配）。
* 当一个接口存在多个实现类的情况下，`@Autowired` 和 `@Resource`都需要通过名称才能正确匹配到对应的 Bean。`Autowired` 可以通过 `@Qualifier` 注解来显式指定名称，`@Resource`可以通过 `name` 属性来显式指定名称。

### Bean的作用域

Spring 中 Bean 的作用域通常有下面几种：

* **singleton** : IoC 容器中只有唯一的 bean 实例。Spring 中的 bean 默认都是单例的，是对单例设计模式的应用。
* **prototype** : 每次获取都会创建一个新的 bean 实例。也就是说，连续 `getBean()` 两次，得到的是不同的 Bean 实例。
* **request** （仅 Web 应用可用）: 每一次 HTTP 请求都会产生一个新的 bean（请求 bean），该 bean 仅在当前 HTTP request 内有效。
* **session** （仅 Web 应用可用） : 每一次来自新 session 的 HTTP 请求都会产生一个新的 bean（会话 bean），该 bean 仅在当前 HTTP session 内有效。
* **application/global-session** （仅 Web 应用可用）： 每个 Web 应用在启动时创建一个 Bean（应用 Bean），该 bean 仅在当前应用启动时间内有效。
* **websocket** （仅 Web 应用可用）：每一次 WebSocket 会话产生一个新的 bean。

### Bean的线程安全问题

https://baijiahao.baidu.com/s?id=1682143925807971655&wfr=spider&for=pc

大部分时候我们并没有在项目中使用多线程，所以很少有人会关注这个问题。单例 Bean 存在线程问题，主要是因为当多个线程操作同一个对象的时候是存在资源竞争的。

常见的有两种解决办法：

1. 在 Bean 中尽量避免定义可变的成员变量。
2. 在类中定义一个 `ThreadLocal` 成员变量，将需要的可变成员变量保存在 `ThreadLocal` 中（推荐的一种方式）。

不过，大部分 Bean 实际都是无状态（没有实例变量）的（比如 Dao、Service），这种情况下， Bean 是线程安全的。

### Bean的生命周期

> 下面的内容整理自：[https://yemengying.com/2016/07/14/spring-bean-life-cycle/open in new window](https://yemengying.com/2016/07/14/spring-bean-life-cycle/) ，除了这篇文章，再推荐一篇很不错的文章 ：[https://www.cnblogs.com/zrtqsk/p/3735273.htmlopen in new window](https://www.cnblogs.com/zrtqsk/p/3735273.html) 。

* Bean 容器找到配置文件中 Spring Bean 的定义。
* Bean 容器利用 Java Reflection API 创建一个 Bean 的实例。
* 如果涉及到一些属性值 利用 `set()`方法设置一些属性值。
* 如果 Bean 实现了 `BeanNameAware` 接口，调用 `setBeanName()`方法，传入 Bean 的名字。
* 如果 Bean 实现了 `BeanClassLoaderAware` 接口，调用 `setBeanClassLoader()`方法，传入 `ClassLoader`对象的实例。
* 如果 Bean 实现了 `BeanFactoryAware` 接口，调用 `setBeanFactory()`方法，传入 `BeanFactory`对象的实例。
* 与上面的类似，如果实现了其他 `*.Aware`接口，就调用相应的方法。
* 如果有和加载这个 Bean 的 Spring 容器相关的 `BeanPostProcessor` 对象，执行 `postProcessBeforeInitialization()` 方法
* 如果 Bean 实现了 `InitializingBean`接口，执行 `afterPropertiesSet()`方法。
* 如果 Bean 在配置文件中的定义包含 init-method 属性，执行指定的方法。
* 如果有和加载这个 Bean 的 Spring 容器相关的 `BeanPostProcessor` 对象，执行 `postProcessAfterInitialization()` 方法
* 当要销毁 Bean 的时候，如果 Bean 实现了 `DisposableBean` 接口，执行 `destroy()` 方法。
* 当要销毁 Bean 的时候，如果 Bean 在配置文件中的定义包含 destroy-method 属性，执行指定的方法。

图示：

![Spring Bean 生命周期](https://images.xiaozhuanlan.com/photo/2019/24bc2bad3ce28144d60d9e0a2edf6c7f.jpg)

与之比较类似的中文版本:

![Spring Bean 生命周期](https://images.xiaozhuanlan.com/photo/2019/b5d264565657a5395c2781081a7483e1.jpg)

## Spring AOP

实现原理：动态代理https://www.cnblogs.com/gonjan-blog/p/6685611.html

https://blog.csdn.net/DDDYSz/article/details/123378554

https://www.cnblogs.com/lyj-gyq/p/8907132.html

https://blog.csdn.net/weixin_46228112/article/details/124725186

**AspectJ定义的通知类型有：**

* **Before** （前置通知）：目标对象的方法调用之前触发
* **After** （后置通知）：目标对象的方法调用之后触发
* **AfterReturning** （返回通知）：目标对象的方法调用完成，在返回结果值之后触发
* **AfterThrowing** （异常通知） ：目标对象的方法运行中抛出 / 触发异常后触发。AfterReturning 和 AfterThrowing 两者互斥。如果方法调用成功无异常，则会有返回值；如果方法抛出了异常，则不会有返回值。
* **Around** （环绕通知）：编程式控制目标对象的方法调用。环绕通知是所有通知类型中可操作范围最大的一种，因为它可以直接拿到目标对象，以及要执行的方法，所以环绕通知可以任意的在目标对象的方法调用前后搞事，甚至不调用目标对象的方法

AOP中 @Before @After @AfterThrowing@AfterReturning的执行顺序：

```java
 1 public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
 2    Object result;
 3    try {
 4        //@Before
 5        result = method.invoke(target, args);
 6        //@After
 7        return result;
 8    } catch (InvocationTargetException e) {
 9        Throwable targetException = e.getTargetException();
10        //@AfterThrowing
11        throw targetException;
12    } finally {
13        //@AfterReturning
14    }
15 }
```

多个切面的执行顺序使用 `@Order`定义：

```java
// 值越小优先级越高
@Order(3)
@Component
@Aspect
public class LoggingAspect implements Ordered {

```

## SpringMVC

MVC 是一种设计模式，Spring MVC 是一款很优秀的 MVC 框架。Spring MVC 可以帮助我们进行更简洁的 Web 层的开发，并且它天生与 Spring 框架集成。Spring MVC 下我们一般把后端项目分为 Service 层（处理业务）、Dao 层（数据库操作）、Entity 层（实体类）、Controller 层(控制层，返回数据给前台页面)。

### Spring MVC 的核心组件

记住了下面这些组件，也就记住了 SpringMVC 的工作原理。

* **`DispatcherServlet`** ： **核心的中央处理器** ，负责接收请求、分发，并给予客户端响应。
* **`HandlerMapping`** ： **处理器映射器** ，根据 uri 去匹配查找能处理的 `Handler` ，并会将请求涉及到的拦截器和 `Handler` 一起封装。
* **`HandlerAdapter`** ： **处理器适配器** ，根据 `HandlerMapping` 找到的 `Handler` ，适配执行对应的 `Handler`；
* **`Handler`** ： **请求处理器** ，处理实际请求的处理器。
* **`ViewResolver`** ： **视图解析器** ，根据 `Handler` 返回的逻辑视图 / 视图，解析并渲染真正的视图，并传递给 `DispatcherServlet` 响应客户端

**Spring MVC 原理如下图所示：**

> SpringMVC 工作原理的图解我没有自己画，直接图省事在网上找了一个非常清晰直观的，原出处不明。

![](https://img-blog.csdnimg.cn/img_convert/de6d2b213f112297298f3e223bf08f28.png)

**流程说明（重要）：**

1. 客户端（浏览器）发送请求， `DispatcherServlet`拦截请求。
2. `DispatcherServlet` 根据请求信息调用 `HandlerMapping` 。`HandlerMapping` 根据 uri 去匹配查找能处理的 `Handler`（也就是我们平常说的 `Controller` 控制器） ，并会将请求涉及到的拦截器和 `Handler` 一起封装。
3. `DispatcherServlet` 调用 `HandlerAdapter`适配执行 `Handler` 。
4. `Handler` 完成对用户请求的处理后，会返回一个 `ModelAndView` 对象给 `DispatcherServlet`，`ModelAndView` 顾名思义，包含了数据模型以及相应的视图的信息。`Model` 是返回的数据对象，`View` 是个逻辑上的 `View`。
5. `ViewResolver` 会根据逻辑 `View` 查找实际的 `View`。
6. `DispaterServlet` 把返回的 `Model` 传给 `View`（视图渲染）。
7. 把 `View` 返回给请求者（浏览器）

## SpringBoot

### 介绍Spring Boot的启动流程 作者：吾之利剑 https://www.bilibili.com/read/cv16046955 出处：bilibili

大致流程:

    1、获取SpringapplicationListener监听器；

    2、启动所获取到的所有监听器；

    3、初始化ConfigurableEnvironment（配置文件）；

    4、打印Banner图标；

    5、创建容器ConfigurableapplicationContext；

    6、准备容器ConfigurableapplicationContext；

    7、初始化容器ConfigurableapplicationContext；

    8、监听器通知容器启动完成；

    9、监听器通知容器正在运行；

### @SpringBootApplication由那些注解组成

- @SpringBootConfiguration():代表当前是一个配置类
- @EnableAutoConfiguration(): 启动自动配置
- @ComponentScan()：指定扫描哪些Spring注解

### 自动配置原理

SpringBoot使用@EnableAutoConfiguration注解开启自动配置：

1. SpringBoot启动的时候加载主配置类，开启了自动配置功能@EnableAutoConfiguration。
2. 查看@EnableAutoConfiguration，其作用是利用AutoConfigurationImportSelector给容器中导入一些组件。
3. 查看AutoConfigurationImportSelector，其中public String[] selectImports(AnnotationMetadata annotationMetadata)方法内 最终调用getCandidateConfigurations()方法
4. 查看 getCandidateConfigurations(AnnotationMetadata metadata,     AnnotationAttributes attributes)，获取候选的配置，这个是扫描所有jar包类路径下"META-INF/spring.factories"
5. 然后把扫描到的这些文件包装成Properties对象。
6. 从properties中获取到EnableAutoConfiguration.class类名对应的值，然后把他们添加在容器中。

简而言之，整个过程就是将类路径下"META-INF/spring.factories"里面配置的所有EnableAutoConfiguration的值加入到容器中。

### 应用程序的安全性

### 监视器actuator

### swagger

### **异常处理**

### **RequestMapping和GetMapping的不同之处**

### **定时任务**

#### @Scheduled 注解

#### Quartz

### 开启SpringBoot特性的方式

### 读取配置的方式

### Spring Security和Shiro比较

#### Shiro认证的基本流程

流程如下：

> 1. Shiro把用户的数据封装成标识token，token一般封装着用户名，密码等信息
> 2. 使用Subject门面获取到封装着用户的数据的标识token SessionManager会话管理，shiro框架定义了一套会话管理，它不依赖web容器的session，所以shiro 可以使用在非web应用上，也可以将分布式应用的会话集中在一点管理，此特性可使它实现单点登录。 SessionDAO即会话dao，是对session会话操作的一套接口 比如: 可以通过jdbc将会话存储到数据库 也可以把session存储到缓存服务器 CacheManager缓存管理，将用户权限数据存储在缓存，这样可以提高性能 Cryptography密码管理，shiro提供了一套加密/解密的组件，方便开发。比如提供常用的散列、加/解密等功能
> 3. Subject把标识token交给SecurityManager，在SecurityManager安全中心中，SecurityManager 把标识token委托给认证器Authenticator进行身份验证。认证器的作用一般是用来指定如何验证，它规定本次认证用到哪些Realm
> 4. 认证器Authenticator将传入的标识token，与数据源Realm对比，验证token是否合法
>    ![认证流程](https://img-blog.csdnimg.cn/10a0fff462e64d56bff8670305c7322f.png)

#### shiro身份授权的基本流程

流程如下：

> 1. 首先调用Subject.isPermitted/hasRole接口，其会委托给SecurityManager。
> 2. SecurityManager接着会委托给内部组件Authorizer；
> 3. Authorizer再将其请求委托给我们的Realm去做；Realm才是真正干活的；
> 4. Realm将用户请求的参数封装成权限对象。再从我们重写的doGetAuthorizationInfo方法中获取从 数据库中查询到的权限集合。
> 5. Realm将用户传入的权限对象，与从数据库中查出来的权限对象，进行一一对比。如果用户传入的 权限对象在从数据库中查出来的权限对象中，则返回true，否则返回false。 进行授权操作的前提：用户必须通过认证。
>    ![授权流程](https://img-blog.csdnimg.cn/97bb174ddc5d4bd68f52cfda1d0e574a.png)

Shiro特点

> 内置的基于 POJO 企业会话管理，适用于 Web 以及非 Web 的环境；
> 异构客户端会话访问；
> 非常简单的加密 API；
> 不跟任何的框架或者容器捆绑，可以独立运行。

Spring Security特点

> 不能脱离Spring；
> spring-security对spring结合较好，项目是spring-boot等搭建的，使用起来更加方便；
> 有更好的spring社区进行支持；
> 支持oauth授权。

相同点：

> 认证功能
> 授权功能
> 加密功能
> 会话管理
> 缓存支持

不同点：

> Spring Security是一个重量级的安全管理框架；Shiro则是一个轻量级的安全管理框架
> Spring Security 基于Spring开发，项目若使用Spring作为基础，配合Spring Security 做权限更便捷，而Shiro需要和Spring 进行整合开发；
> Spring Security 功能比Shiro更加丰富些，例如安全维护方面；
> Spring Security 社区资源相对于Shiro更加丰富；
> Shiro 的配置和使用比较简单，Spring Security 上手复杂些；
> Shiro 依赖性低，不需要任何框架和容器，可以独立运行， Spring Security依赖Spring容器；
> Shiro 不仅仅可以使用在web中，它可以工作在任何应用环境中。在集群会话时Shiro最重要的一个好处或许就是它的会话是独立于容器的；

版权声明：本文为CSDN博主「HarrisDong」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/DQWERww/article/details/126689773

### 如何解决跨域问题

- 重写 `WebMvcConfigurer.addCorsMappings()`
- @CrossQrigin注解
- 使用 `Filter`过滤器

### 性能优化

1. 如果项目比较大，类比较多，不使用@SpringBootApplication，采用@Compoment指定扫包范围
2. 在项目启动时设置JVM初始内存和最大内存相同
3. 将springboot内置服务器由tomcat设置为undertow

- spring的IOC创建出来的对象的的作用域有哪些
- 面向切面(AOP)和控制反转(IOC)
- spring单例对象的线程安全问题如何处理
- ORM框架用什么
- mybatis
- mysql隔离级别
- 脏读幻读
- 数据库死锁
- 数据库优化
- 索引失效情况
- 数据库分表策略，垂直分表、水平分表、慢查询、
- 索引类型
- redis缓存与数据库的双写一致性
- rdb和aof的优缺点
- 借口幂等性
- spring两种动态代理模式AspectJ

# 网络

## OSI七层模型

**OSI 七层模型** 是国际标准化组织提出一个网络分层模型，其大体结构以及每一层提供的功能如下图所示：

![OSI 七层模型](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/cs-basics/network/osi-7-model.png)

每一层都专注做一件事情，并且每一层都需要使用下一层提供的功能比如传输层需要使用网络层提供的路由和寻址功能，这样传输层才知道把数据传输到哪里去。

**OSI 的七层体系结构概念清楚，理论也很完整，但是它比较复杂而且不实用，而且有些功能在多个层中重复出现。**

---

著作权归所有
原文链接：https://javaguide.cn/cs-basics/network/osi&tcp-ip-model.html

## TCP/IP四层模型

TCP/IP模型是OSI模型的精简版：

1. 应用层
   提供两个终端设备上的应用程序之间信息交换的服务，定义快信息交换的格式消息会交给传输层来传输，应用层交换的数据单元称为报文。
2. 传输层
   传输层是负责两台终端设备的进程之间通信提供通用的数据传输服务，应用层利用该服务传输报文，多种应用可以使用同一个传输层服务。主要有TCP协议和UDP协议。
3. 网络层
   网络层负责为分组交换网络上的不同主机提供通信服务。网络层把传输层产生的报文段或用户数据报封装成分组和包进行传送。由于网络层使用IP协议，因此分组也叫IP数据报简称数据报。网络层还有一个任务就是选择路由，使网络层下来的分组能过通过网络层中的路由器找到目的主机。
4. 网络接口层
   网络接口层是数据链路层和物理层的合体。数据链路层将网络层下来的数据报组装成帧，再两个相邻节点间的链路上传送帧。物理层的作用是实现相邻计算机节点之间的比特流的透明传输。

## 应用层常见协议

### HTTP：超文本传输协议

基于TCP协议，目前大部分是HTTP1.1，默认开启keep-alive，一次连接可以发送多次请求。HTTP协议是无状态的，一般使用session来记录客户端用户的状态。

### SMTP：简单邮件传输（发送）协议

基于TCP协议，用来发送邮件。

**电子邮件的发送过程？**

比如我的邮箱是“dabai@cszhinan.com”，我要向“xiaoma@qq.com”发送邮件，整个过程可以简单分为下面几步：

1. 通过 **SMTP** 协议，我将我写好的邮件交给163邮箱服务器（邮局）。
2. 163邮箱服务器发现我发送的邮箱是qq邮箱，然后它使用 SMTP协议将我的邮件转发到 qq邮箱服务器。
3. qq邮箱服务器接收邮件之后就通知邮箱为“xiaoma@qq.com”的用户来收邮件，然后用户就通过 **POP3/IMAP** 协议将邮件取出。

**如何判断邮箱是真正存在的？**

很多场景(比如邮件营销)下面我们需要判断我们要发送的邮箱地址是否真的存在，这个时候我们可以利用 SMTP 协议来检测：

1. 查找邮箱域名对应的 SMTP 服务器地址
2. 尝试与服务器建立连接
3. 连接成功后尝试向需要验证的邮箱发送邮件
4. 根据返回结果判定邮箱地址的真实性

---

著作权归所有
原文链接：https://javaguide.cn/cs-basics/network/application-layer-protocol.html

### POP3/IMAP：邮件接收的协议

不同于SMTP协议，这两个协议是负责接收邮件的。

### FTP：文件传输协议

基于TCP，FTP在两台主机之间使用两条TCP连接：

- 控制连接：用于传输控制信息（命令和响应）
- 数据连接：用于数据传送

### Telnet：远程登录协议

基于TCP协议，通过一个终端登录到其他服务器，建立在可靠TCP连接上，但是缺点是所有的数据（包括用户名和密码）都是以明文传送。如今基本被SSH协议所取代。

### SSH协议：安全的网络传输协议

SSH（Security Shell）是较为可靠的专为远程登录和其他网络服务提供安全性的协议，建立在可靠的TCP协议之上。

## 传输层协议

TCP/UDP

## 网络层协议

### ARP协议

https://blog.csdn.net/jisuanji111111/article/details/128040550?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-0-128040550-blog-126005351.pc_relevant_multi_platform_whitelistv3&spm=1001.2101.3001.4242.1&utm_relevant_index=3

主机A向主机B通信，主机A和主机B在同一个网段时，A检查自己的ARP表，如果B的MAC地址没有在表中则会发送一个ARP协议的广播报文，广播报文中源IP地址为主机A的IP地址，源MAC地址为A的MAC地址，目的IP地址为主机B的IP地址，目的MAC地址为全0，当B接收到广播报文发现目的IP地址为自己主机的IP则将A的信息加入自己的ARP表中，则以单播的形势向A返回一个ARP报文，其中源IP地址和源MAC地址包含自己的IP和MAC信息，A接收到该报文后将B的相应信息加入自己的ARP表，然后开始进行报文转发。

### ICMP协议

差错报文：

1. 目的站不可达
2. 数据报超时（TTL每过下一跳减一）

## 对称加密和非对称加密

https://www.jianshu.com/p/a56b86a8abe0

https://blog.csdn.net/Hell_potato777/article/details/126689101

通信两方A、B，生产各自的

# Java

## Java I/O

I/O即 `Input/Output`，输入输出流，输入到计算机内存为输入，输出到外部

## 深入浅出了理解Java传参原理

https://www.zhihu.com/question/515961668?utm_division=hot_list_page

## java中==和equals和hashCode的区别

==比较的是内存地址，即是否为同一个对象。

equals比较的是对象的内容是否相等

hashcode相等但可能不equals

hashcode不相等则一定不equals

equals表明hashcode一定相等

## int、char、long各占多少字节数

| 类型    | 字节 | 备注                                                                                                               |
| ------- | ---- | ------------------------------------------------------------------------------------------------------------------ |
| byte    | 1    | 8位为一个字节                                                                                                      |
| short   | 2    | 16位、有符号的以二进制补码表示的整数                                                                               |
| char    | 2    | 一个char可以表示并存储一个汉字                                                                                     |
| int     | 4    | 32位、有符号的以二进制补码表示的整数                                                                               |
| long    | 8    | 在int的取值范围之内int与long可以互相转换，如果超出int取值范围需要加"L"进行赋值“long n = 1000000000000L"           |
| float   | 4    | 浮点数默认为double，float类型的赋值需要在末尾加“F"                                                                |
| double  | 8    | 默认的是double类型，如3.14是double类型的，加后缀F（3.14F）则为float类型的。                                        |
| boolean | 1或4 | boolean在数组情况下为1个字节，单个boolean为4个字节。[详见](https://blog.csdn.net/xdian2020/article/details/122110227) |

## 面向对象三大特征

### 封装

封装是指把一个对象的状态信息（也就是属性）隐藏在对象内部，不允许外部对象直接访问对象的内部信息。但是可以提供一些可以被外界访问的方法来操作属性。

### 继承

使用已存在的类的定义作为基础建立新类的技术，新类的定义可以增加新的数据或新的功能，也可以用父类的功能，但不能选择性地继承父类。通过使用继承，可以快速地创建新的类，可以提高代码的重用，程序的可维护性，节省大量创建新类的时间 ，提高我们的开发效率。

### 多态

表示一个对象具有多种的状态，具体表现为父类的引用指向子类的实例。

多态的特点：

* 对象类型和引用类型之间具有继承（类）/实现（接口）的关系；
* 引用类型变量发出的方法调用的到底是哪个类中的方法，必须在程序运行期间才能确定；
* 多态不能调用“只在子类存在但在父类不存在”的方法；
* 如果子类重写了父类的方法，真正执行的是子类覆盖的方法，如果子类没有覆盖父类的方法，执行的是父类的方法。

著作权归所有
原文链接：https://javaguide.cn/java/basis/java-basic-questions-02.html

## 深拷贝、浅拷贝、引用拷贝

### 深拷贝

完全复制整个对象、包括这个对象包含的内部对象。

### 浅拷贝

在堆上创建一个新的对象，但是但是拷贝对象的内部对象如果是引用类型的话，则直接复制内部对象的引用地址。

### 引用拷贝

两个不同的引用指向同一个对象。

## String、StringBuffer、StringBuilder区别

相同点：全部是final修饰，不可被继承

执行速度：StringBuilder > StringBuffer > String

| String                 | StringBuilder                      | StringBuffer                         |
| ---------------------- | ---------------------------------- | ------------------------------------ |
| 不可变                 | 可修改                             | 可修改                               |
|                        | 线程不安全                         | 线程安全内部方法使用synchronized修饰 |
| 操作少量数据使用String | 单线程操作字符串缓冲区下的大量数据 | 多线程操作字符串缓冲区下的大量数据   |

## Java内部类四大作用

- 内部类可以很好的实现隐藏，一般的非内部类，是不允许有 private 与protected权限的，但内部类可以；
- 内部类拥有外围类的所有元素的访问权限；
- 可以实现多重继承，类三里面分别实现了两个内部类 InnerOne,和InnerTwo ，InnerOne类又继承了ExampleOne，InnerTwo继承了ExampleTwo，这样我们的类三MainExample就拥有了ExampleOne和ExampleTwo的方法和属性，也就间接的实现了多重继承；
- 可以避免修改接口而实现同一个类中两种同名方法的调用。子类要继承一个类，还要实现一个接口，但是继承的类和接口里面有两个同名的方法，则使用子类继承父类，同时子类中定义一个内类实现接口。

## 抽象类和接口

https://blog.csdn.net/m0_51358164/article/details/125153230

- 在interface里面的变量默认都是public static final 的。所以可以直接省略修饰符
- Java8中接口中可以添加静态方法和默认方法，静态方法使用static修饰可通过接口直接调用，而且无法在实现类中覆盖静态方法。默认方法使用default修饰可以通过实现类对象来调用，在接口中新增默认方法现有实现类无需覆写该方法。
- 抽象类是对整个类进行抽象，接口是对行为进行抽象，继承是“是不是的关系"而接口是“有没有"的关系

## 泛型中extends和super的区别

https://www.cnblogs.com/yb-ken/p/15084960.html

`<? extends Fruit>`代表的是上界通配符，也就是说这个List中存放的对象都是Fruit以及其子类的对象；

`<? super Fruit>`代表的是下界通配符，也就是说这个List中存放的对象都是Fruit以及其父类的对象；

## final，finally，finalize的区别

final修饰属性、方法和类，表示属性不可变更、方法不可覆盖、类不可继承。finally是异常处理语句结构的一部分表示总是执行。finalize是Object类中的一个方法，在垃圾收集器执行的时候会调用被回收对象的此方法，供资源收集时的其他资源回收，例如文件关闭等。

## Java序列化的几种方式

原文链接：https://blog.csdn.net/qq_35936973/article/details/115700778

### 原生序列化方式

- 实现Serializable 接口（隐式序列化 ），通过实现 Serializable 接口，这种是隐式序列化 ( 不需要手动 ) ，这种是最简单的序列化方式，会自动序列化所有非 static 和 transient 关键字修饰的成员变量。
- 实现Externalizable接口（显式序列化），Externalizable 接口继承自 Serializable, 我们在实现该接口时，必须实现 writeExternal() 和readExternal() 方法，而且只能通过手动进行序列化，并且两个方法是自动调用的，因此，这个序列化过程是可控的，可以自己选择哪些部分序列化。Externalizable 类会调用 public 的构造函数先初始化对象，在调用所保存的内容将对象还原。假如构造方法不是 public 则会出现运行时错误。
- 实现Serializable 接口+添加writeExternal() 和readExternal() 方法（显+隐序列化），注意这里是添加两个方法，而不是重写或覆盖，而且这两个方法必须有特定的格式约定：
  - 方法必须要被 private 修饰 —–> 才能被调用
  - 第一行调用默认的 defaultRead/WriteObject() —–> 隐式序列化非 static 和 transient
  - 调用 read/writeObject() 将获得的值赋给相应的值 —–> 显式序列化

### JSON序列化

Json 序列化一般会使用 jackson 包，通过 ObjectMapper 类来进行一些操作，比如将对象转化为 byte 数组
或者将 json 串转化为对象。现在的大多数公司都将 json 作为服务器端返回的数据格式。比如调用一个服
务器接口，通常的请求为 xxx.json?a=xxx&b=xxx 的形式。

## Java反射

我们知道Spring框架可以帮我们创建和管理对象。需要对象时，我们无需自己手动new对象，直接从Spring提供的容器中的Beans获取即可。Beans底层其实就是一个Map<String,Object>，最终通过getBean(“user”)来获取。而这其中最核心的实现就是利用反射技术。
————————————————
版权声明：本文为CSDN博主「有意悠悠」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/qq_51515673/article/details/124830558

## Java多线程&高并发

多线程的四种实现方式：https://www.cnblogs.com/big-keyboard/p/16813151.html

https://javaguide.cn/java/concurrent/java-concurrent-questions-01.html

一个进程中有多个线程，多个线程共享进程的堆和方法区（JDK1.8之后的元空间Metaspace）资源，但是每个线程有自己的程序计数器，虚拟机栈和本地方法栈。

### 程序计数器、虚拟机栈和本地方法栈为什么是线程私有的

- 程序计数器记录该线程指令的执行位置，当线程被切换回来的时候需要知道将该线程恢复到正确的执行的位置。

* **虚拟机栈：** 每个 Java 方法在执行的同时会创建一个栈帧用于存储局部变量表、操作数栈、常量池引用等信息。从方法调用直至执行完成的过程，就对应着一个栈帧在 Java 虚拟机栈中入栈和出栈的过程。
* **本地方法栈：** 和虚拟机栈所发挥的作用非常相似，区别是： **虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 [Native方法](https://www.cnblogs.com/szlbm/p/5504603.html) 服务。** 在 [HotSpot虚拟机](https://blog.csdn.net/xing_jian1/article/details/122949080) 中和 Java 虚拟机栈合二为一。

所以，为了 **保证线程中的局部变量不被别的线程访问到** ，虚拟机栈和本地方法栈是线程私有的。

### 堆和方法区

堆和方法区是线程共享的资源，其中堆是进程中的一大块内存，主要用于存放新创建的对象（几乎所有的对象都在这里分配内存），方法区主要用于存放已被加载的类信息、常量、静态变量、已被即时编译器编译后的代码等数据。

### 线程的生命周期和状态

Java 线程在运行的生命周期中的指定时刻只可能处于下面 6 种不同状态的其中一个状态：

* NEW: 初始状态，线程被创建出来但没有被调用 `start()` 。
* RUNNABLE：运行状态，线程被调用了 `start()`等待运行的状态。
* BLOCKED ：阻塞状态，需要等待锁释放。
* WAITING：等待状态，表示该线程需要等待其他线程做出一些特定动作（通知或中断）。
* TIME_WAITING：超时等待状态，可以在指定的时间后自行返回而不是像 WAITING 那样一直等待。
* TERMINATED：终止状态，表示该线程已经运行完毕。

线程在生命周期中并不是固定处于某一个状态而是随着代码的执行在不同状态之间切换。

Java 线程状态变迁图(图源：[挑错 |《Java 并发编程的艺术》中关于线程状态的三处错误open in new window](https://mp.weixin.qq.com/s/UOrXql_LhOD8dhTq_EPI0w))：

![Java 线程状态变迁图](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/java/concurrent/640.png)

由上图可以看出：线程创建之后它将处于 **NEW（新建）** 状态，调用 `start()` 方法后开始运行，线程这时候处于 **READY（可运行）** 状态。可运行状态的线程获得了 CPU 时间片（timeslice）后就处于 **RUNNING（运行）** 状态。

> 在操作系统层面，线程有 READY 和 RUNNING 状态；而在 JVM 层面，只能看到 RUNNABLE 状态（图源：[HowToDoInJavaopen in new window](https://howtodoinJava.com/ "HowToDoInJava")：[Java Thread Life Cycle and Thread Statesopen in new window](https://howtodoinJava.com/Java/multi-threading/Java-thread-life-cycle-and-thread-states/ "Java Thread Life Cycle and Thread States")），所以 Java 系统一般将这两个状态统称为 **RUNNABLE（运行中）** 状态 。
>
> **为什么 JVM 没有区分这两种状态呢？** （摘自：[Java 线程运行怎么有第六种状态？ - Dawell 的回答open in new window](https://www.zhihu.com/question/56494969/answer/154053599) ） 现在的时分（time-sharing）多任务（multi-task）操作系统架构通常都是用所谓的“时间分片（time quantum or time slice）”方式进行抢占式（preemptive）轮转调度（round-robin 式）。这个时间分片通常是很小的，一个线程一次最多只能在 CPU 上运行比如 10-20ms 的时间（此时处于 running 状态），也即大概只有 0.01 秒这一量级，时间片用后就要被切换下来放入调度队列的末尾等待再次调度。（也即回到 ready 状态）。线程切换的如此之快，区分这两种状态就没什么意义了。

![RUNNABLE-VS-RUNNING](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-3/RUNNABLE-VS-RUNNING.png)

* 当线程执行 `wait()`方法之后，线程进入 **WAITING（等待）** 状态。进入等待状态的线程**需要依靠其他线程的通知**才能够返回到运行状态。
* **TIMED_WAITING(超时等待)** 状态相当于在等待状态的基础上增加了超时限制，比如通过 `sleep（long millis）`方法或 `wait（long millis）`方法可以将线程置于 TIMED_WAITING 状态。当超时时间结束后，线程将会返回到 RUNNABLE 状态。
* 当线程进入 `synchronized` 方法/块或者调用 `wait` 后（被 `notify`）重新进入 `synchronized` 方法/块，但是锁被其它线程占有，这个时候线程就会进入 **BLOCKED（阻塞）** 状态。
* 线程在执行完了 `run()`方法之后将会进入到 **TERMINATED（终止）** 状态。

相关阅读：[线程的几种状态你真的了解么？open in new window](https://mp.weixin.qq.com/s/R5MrTsWvk9McFSQ7bS0W2w) 。

### 上下文切换的几种情况

线程在执行过程中会有自己的运行条件和状态（也称上下文），比如上文所说到过的程序计数器，栈信息等。当出现如下情况的时候，线程会从占用 CPU 状态中退出。

* 主动让出 CPU，比如调用了 `sleep()`, `wait()` 等。
* 时间片用完，因为操作系统要防止一个线程或者进程长时间占用 CPU 导致其他线程或者进程饿死。
* 调用了阻塞类型的系统中断，比如请求 IO，线程被阻塞。
* 被终止或结束运行

这其中前三种都会发生线程切换，线程切换意味着需要保存当前线程的上下文，留待线程下次占用 CPU 的时候恢复现场。并加载下一个将要占用 CPU 的线程上下文。这就是所谓的  **上下文切换** 。

上下文切换是现代操作系统的基本功能，因其每次需要保存信息恢复信息，这将会占用 CPU，内存等系统资源进行处理，也就意味着效率会有一定损耗，如果频繁切换就会造成整体效率低下。

### 什么是死锁

线程死锁描述的是这样一种情况：多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。由于线程被无限期地阻塞，因此程序不可能正常终止。例如：线程 A 持有资源 2，线程 B 持有资源 1，他们同时都想申请对方的资源，所以这两个线程就会互相等待而进入死锁状态。

死锁的四个必要条件：

- 互斥条件：该资源任意时刻只由一个线程占用；
- 请求与保持条件：一个线程因请求资源而阻塞时，对现有资源保持不放；
- 不剥夺条件：线程已获得的资源在未使用完成之前不能被其他线程剥夺，只有自己使用完毕后才会释放资源；
- 循环等待条件：若干线程之间形成一种头尾相连的循环等待资源关系。

如何避免死锁：

- 破坏请求与保持条件：一次性申请所有资源；
- 破坏不剥夺条件：占用部分资源的线程进一步申请其他资源时，如果申请不到可以主动释放现有资源；
- 破坏循环等待条件：靠按序申请资源来预防。按照某一顺序申请资源，释放资源则反序释放，破坏循环等待条件。

### sleep()和wait()区别

相同点：都可以暂停线程的执行。

区别：

- `sleep()`方法没有释放锁，而 `wait()`释放了锁；
- `wait()`经常用于线程间的交互/通信，`sleep()`同于暂停线程；
- `wait()`方法被暂停后不会主动苏醒，需要别的线程调用同一个对象上的 `notify()`或 `notifyAll()`方法。`sleep()`方法执行完之后线程会自动苏醒；
- `sleep()`是Thread类的静态本地的方法，而 `wait()`是Object类的本地方法。

### 可以直接调用 Thread 类的 run 方法吗？

这是另一个非常经典的 Java 多线程面试问题，而且在面试中会经常被问到。很简单，但是很多人都会答不上来！

new 一个 `Thread`，线程进入了新建状态。调用 `start()`方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 `start()` 会执行线程的相应准备工作，然后自动执行 `run()` 方法的内容，这是真正的多线程工作。 但是，直接执行 `run()` 方法，会把 `run()` 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。

**总结： 调用 `start()` 方法方可启动线程并使线程进入就绪状态，直接执行 `run()` 方法的话不会以多线程的方式执行。**

---

著作权归所有
原文链接：https://javaguide.cn/java/concurrent/java-concurrent-questions-01.html

### 悲观锁和乐观锁

https://blog.csdn.net/xx12321q/article/details/124925441

#### 悲观锁

悲观锁是假设最坏的情况，每次在获取资源的时候就会上锁，其他线程想要持有这个资源的时候就会阻塞，直到上一个线程将锁释放。`synchronized `和 `ReentrantLock`等独占锁就是悲观锁的实现。

悲观锁通常用于写比较多的情况。

#### 乐观锁

乐观锁总是假设最好的情况，认为共享资源每次被访问的时候都不会出现问题，线程可以不停的执行，无需加锁也无需等待，只是在提交修改的时候去验证对应的资源是否已经被其他资源修改（验证方法可使用版本号机制或CAS算法）。

在 Java 中 `java.util.concurrent.atomic`包下面的原子变量类就是使用了乐观锁的一种实现方式 **CAS** 实现的。

**乐观锁通常多于写比较少的情况下（多读场景），避免频繁加锁影响性能，大大提升了系统的吞吐量。**

CAS（Compare And Swap）是一个原子操作，底层依赖于一条CPU的原子指令，涉及到三个操作数：

* **V** ：要更新的变量值(Var)
* **E** ：预期值(Expected)
* **N** ：拟写入的新值(New)

当且仅当 V 的值等于 E 时，CAS 通过原子方式用新值 N 来更新 V 的值。如果不等，说明已经有其它线程更新了V，则当前线程放弃更新。

---

著作权归所有
原文链接：https://javaguide.cn/java/concurrent/java-concurrent-questions-02.html

### volatile关键字的作用

`volatile`是Java中的一个类型修饰符。它是被设计用来修饰被不同线程访问和修改的变量。如果不加入volatile，基本上会导致这样的结果：要么无法编写多线程程序，要么编译器失去大量优化的机会。

它主要有两个作用：

- 保证变量的可见性；
- 禁止指令的重排序。

### synchronized关键字

保证任意时刻，被它修饰的方法或代码块只能有一个线程执行。

#### 1.修饰实例方法（锁当前对象实例）

给当前实例对象加锁，进入代码块前需要获得当前实例对象的锁。

#### 2.修饰静态方法（锁当前类）

给当前类加锁，会作用于类的所有对象实例 ，进入同步代码前要获得  **当前 class 的锁** 。

这是因为静态成员不属于任何一个实例对象，归整个类所有，不依赖于类的特定实例，被类的所有实例共享。

#### 3.修饰代码块（锁指定对象/类）

对括号里指定的对象/类加锁：

* `synchronized(object)` 表示进入同步代码库前要获得  **给定对象的锁** ；
* `synchronized(类.class)` 表示进入同步代码前要获得 **给定 Class 的锁。**

**总结：**

* `synchronized` 关键字加到 `static` 静态方法和 `synchronized(class)` 代码块上都是是给 Class 类上锁；
* `synchronized` 关键字加到实例方法上是给对象实例上锁；
* 尽量不要使用 `synchronized(String a)` 因为 JVM 中，字符串常量池具有缓存功能。

### synchronized、Lock、Redission分布式锁

synchronized机制为执行完成相应代码后会自动释放同步监视器，而Lock无论是获取锁还是释放锁都需要手动操作（使用 `lock()`和 `unlock()`方法），所以更为灵活，而且Lock中有 `trylock()`方法，通过该方法可以实现，当前线程没有获取到锁时（`tryLock()`返回false）可以直接向下执行而不是阻塞。

分布式锁是分布式环境下使用的锁，分布式环境下锁放在本地不会起作用，于是将锁和服务分开来部署做成公共组件，来解决资源共享的问题。

### ThreadLocal

通常情况下，我们创建的变量是可以被任何一个线程访问并修改的。使用**ThreadLocal可以实现每一个线程都有自己的专属本地变量。**

ThreadLocal实现原理：

最终的变量放在当前线程的 `ThreadLocalMap`里，`ThreadLocalMap`是 `ThreadLocal`类实现的定制化 `HashMap`，**`ThreadLocal` 可以理解为只是 `ThreadLocalMap`的封装，传递了变量值。**`ThrealLocal` 类中可以通过 `Thread.currentThread()`获取到当前线程对象后，直接通过 `getMap(Thread t)`可以访问到该线程的 `ThreadLocalMap`对象。**每个 `Thread`中都具备一个 `ThreadLocalMap`，而 `ThreadLocalMap`可以存储以 `ThreadLocal`为 key ，Object 对象为 value 的键值对。**

ThreadLocal内存泄漏原理：

`ThreadLocalMap` 中使用的 key 为 `ThreadLocal` 的弱引用，而 value 是强引用。所以，如果 `ThreadLocal` 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。

这样一来，`ThreadLocalMap` 中就会出现 key 为 null 的 Entry。假如我们不做任何措施的话，value 永远无法被 GC 回收，这个时候就可能会产生内存泄露。`ThreadLocalMap` 实现中已经考虑了这种情况，在调用 `set()`、`get()`、`remove()` 方法的时候，会清理掉 key 为 null 的记录。使用完 `ThreadLocal`方法后 最好手动调用 `remove()`方法。

### MDC、ThreadLoacl、InheritableThreadLocal的区别与联系

https://blog.csdn.net/qq_33247435/article/details/127793733

### Atomic原子类

所谓原子类说简单点就是具有原子/原子操作特征的类。

并发包 `java.util.concurrent` 的原子类都存放在 `java.util.concurrent.atomic`下,如下图所示。

![JUC原子类概览](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/JUC原子类概览.png)

根据操作的数据类型，可以将 JUC 包中的原子类分为 4 类

**基本类型**

使用原子的方式更新基本类型

* `AtomicInteger`：整型原子类
* `AtomicLong`：长整型原子类
* `AtomicBoolean` ：布尔型原子类

**数组类型**

使用原子的方式更新数组里的某个元素

* `AtomicIntegerArray`：整型数组原子类
* `AtomicLongArray`：长整型数组原子类
* `AtomicReferenceArray` ：引用类型数组原子类

**引用类型**

* `AtomicReference`：引用类型原子类
* `AtomicMarkableReference`：原子更新带有标记的引用类型。该类将 boolean 标记与引用关联起来， ~也可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题~ 。
* `AtomicStampedReference` ：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于解决原子的更新数据和数据的版本号，可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题。

**🐛 修正（参见：[issue#626open in new window](https://github.com/Snailclimb/JavaGuide/issues/626)）** : `AtomicMarkableReference` 不能解决 ABA 问题。

**对象的属性修改类型**

* `AtomicIntegerFieldUpdater`:原子更新整型字段的更新器
* `AtomicLongFieldUpdater`：原子更新长整型字段的更新器
* `AtomicReferenceFieldUpdater`：原子更新引用类型里的字段

### ABA问题

当执行campare and swap会出现失败的情况。例如，一个线程先读取共享内存数据值A，随后因某种原因，线程暂时挂起，同时另一个线程临时将共享内存数据值先改为B，随后又改回为A。随后挂起线程恢复，并通过CAS比较，最终比较结果将会无变化。这样会通过检查，这就是ABA问题。 在CAS比较前会读取原始数据，随后进行原子CAS操作。这个间隙之间由于并发操作，最终可能会带来问题。
————————————————
版权声明：本文为CSDN博主「GodOfCode_」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/huangquan__/article/details/116241700

### 线程池创建方式

#### 方式一：通过构造方法创建。

**`ThreadPoolExecutor` 3 个最重要的参数：**

* **`corePoolSize` :** 核心线程数定义了最小可以同时运行的线程数量。
* **`maximumPoolSize` :** 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。
* **`workQueue`:** 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。

`ThreadPoolExecutor`其他常见参数:

1. **`keepAliveTime`** :当线程池中的线程数量大于 `corePoolSize` 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 `keepAliveTime`才会被回收销毁；
2. **`unit`** : `keepAliveTime` 参数的时间单位。
3. **`threadFactory`** :executor 创建新线程的时候会用到。
4. **`handler`** :饱和策略。关于饱和策略下面单独介绍一下。

#### 方式二：通过Executor框架的工具类Executors来实现

我们可以创建三种类型的 ThreadPoolExecutor：

* **FixedThreadPool** ： 该方法返回一个固定线程数量的线程池。该线程池中的线程数量始终不变。当有一个新的任务提交时，线程池中若有空闲线程，则立即执行。若没有，则新的任务会被暂存在一个任务队列中，待有线程空闲时，便处理在任务队列中的任务。
* **SingleThreadExecutor：** 方法返回一个只有一个线程的线程池。若多余一个任务被提交到该线程池，任务会被保存在一个任务队列中，待线程空闲，按先入先出的顺序执行队列中的任务。
* **CachedThreadPool：** 该方法返回一个可根据实际情况调整线程数量的线程池。线程池的线程数量不确定，但若有空闲线程可以复用，则会优先使用可复用的线程。若所有线程均在工作，又有新的任务提交，则会创建新的线程处理任务。所有线程在当前任务执行完毕后，将返回线程池进行复用。

> Executors 返回线程池对象的弊端如下：
>
> * **FixedThreadPool 和 SingleThreadExecutor** ： 允许请求的队列长度为 Integer.MAX_VALUE ，可能堆积大量的请求，从而导致 OOM。
> * **CachedThreadPool 和 ScheduledThreadPool** ： 允许创建的线程数量为 Integer.MAX_VALUE ，可能会创建大量线程，从而导致 OOM。

#### 线程池饱和策略

* **`ThreadPoolExecutor.AbortPolicy`：** 抛出 `RejectedExecutionException`来拒绝新任务的处理。
* **`ThreadPoolExecutor.CallerRunsPolicy`：** 调用执行自己的线程运行任务，也就是直接在调用 `execute`方法的线程中运行(`run`)被拒绝的任务，如果执行程序已关闭，则会丢弃该任务。因此这种策略会降低对于新任务提交速度，影响程序的整体性能。如果您的应用程序可以承受此延迟并且你要求任何一个任务请求都要被执行的话，你可以选择这个策略。
* **`ThreadPoolExecutor.DiscardPolicy`：** 不处理新任务，直接丢弃掉。
* **`ThreadPoolExecutor.DiscardOldestPolicy`：** 此策略将丢弃最早的未处理的任务请求。

## Java集合

https://javaguide.cn/java/collection/java-collection-questions-01.html

概述：Java 集合， 也叫作容器，主要是由两大接口派生而来：一个是 `Collection`接口，主要用于存放单一元素；另一个是 `Map` 接口，主要用于存放键值对。对于 `Collection` 接口，下面又有三个主要的子接口：`List`、`Set` 和 `Queue`。

### Collection

#### List

- `ArrayList`：`List `的主要实现类，使用 `Object[]`存储，线程不安全；
  - `ArrayList`扩容机制：初始容量为10，添加第11个元素时，扩容至1.5倍。
- `Vector`：`List`的古老实现类，使用 `Object[]`存储，线程安全；
- `LinkedList`：双向链表实现（1.6之前为双向循环链表），线程不安全。

#### Set

`HashSet`、`LinkedHashSet` 和 `TreeSet`：

* `HashSet`、`LinkedHashSet` 和 `TreeSet` 都是 `Set` 接口的实现类，都能保证元素唯一，并且都不是线程安全的。
* `HashSet`、`LinkedHashSet` 和 `TreeSet` 的主要区别在于底层数据结构不同。`HashSet` 的底层数据结构是哈希表（基于 `HashMap` 实现）。`LinkedHashSet` 的底层数据结构是链表和哈希表，元素的插入和取出顺序满足 FIFO。`TreeSet` 底层数据结构是红黑树，元素是有序的，排序的方式有自然排序和定制排序。
* 底层数据结构不同又导致这三者的应用场景不同。`HashSet` 用于不需要保证元素插入和取出顺序的场景，`LinkedHashSet` 用于保证元素的插入和取出顺序满足 FIFO 的场景，`TreeSet` 用于支持对元素自定义排序规则的场景。

#### Queue

- `Queue`：单端队列，只能从一端插入，另一端删除，遵循先进先出（FIFO）规则；
- `Deque`：双端队列，两端都可以插入或删除；
- `ArrayDeque`：实现Deque接口，基于可变长的数组和双指针实现，不支持存储NULL数据，插入时可能存在扩容情况，不过均摊后性能为O(1)；
- `LinkedList`：实现Deque接口，基于链表实现，支持NULL数据，不需要扩容但每次插入需要申请新的堆空间，性能比 `ArrayDeque`差。
- `PriorityQueue`：优先级队列，总是优先级最高的元素先出队。

### Map

- `HashMap`：非线程安全，允许null-key和null-value，默认初始大小为16，每次扩容变为原来的二倍；
  - JDK1.8 以后的 `HashMap` 在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）时，将链表转化为红黑树（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树），以减少搜索时间。
- `HashTable`：线程安全，方法使用synchorized修饰，不允许null-key和null-value，默认初始大小为11，每次扩容为2n+1，性能较差，建议使用 `ConcurrentHashMap`；
- `TreeMap`：按照key升序排列；

## JVM

### 运行时数据区域

Java 虚拟机在执行 Java 程序的过程中会把它管理的内存划分成若干个不同的数据区域。JDK 1.8 和之前的版本略有不同，下面会介绍到。

**JDK 1.8 之前** ：

![Java 运行时数据区域（JDK1.8 之前）](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/java/jvm/java-runtime-data-areas-jdk1.7.png)

**JDK 1.8 之后** ：

![Java 运行时数据区域（JDK1.8 之后）](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/java/jvm/java-runtime-data-areas-jdk1.8.png)

**线程私有的：**

* 程序计数器
* 虚拟机栈
* 本地方法栈

**线程共享的：**

* 堆
* 方法区
* 直接内存 (非运行时数据区的一部分)

Java 虚拟机规范对于运行时数据区域的规定是相当宽松的。以堆为例：堆可以是连续空间，也可以不连续。堆的大小可以固定，也可以在运行时按需扩展 。虚拟机实现者可以使用任何垃圾回收算法管理堆，甚至完全不进行垃圾收集也是可以的。

#### 程序计数器

程序计数器是唯一一个不会出现 `OutOfMemoryError`异常的内存区域，它是生命周期随着线程的创建而创建，随着线程的消亡而消亡。

#### Java虚拟机栈

与程序计数器一样java虚拟机栈也是线程私有的，生命周期和线程相同。除了Native方法，其他所有的Java方法调用都是通过栈来实现的。栈由一个个栈帧组成，每个栈帧中都有：局部变量表、操作数栈、动态链接、方法返回地址。

#### 本地方法栈

和虚拟机栈所发挥的作用非常类似，区别是：虚拟机栈执行Java方法（也就是字节码）服务，而本地方法栈则为虚拟机使用到的Native方法服务。在HotSpot虚拟机中和Java虚拟机栈合二为一。

#### 堆

 Java虚拟机所管理的内存中最大的一块，Java堆是所有线程共享的一块区域，在虚拟机创建时使用。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存。

Java堆是垃圾收集器管理的主要区域，因此也被称作GC堆（Garbage Collected Heap）。

#### 方法区

方法区是属于运行时数据区域的一块逻辑区域，是各个线程共享的区域。

当虚拟机要使用一个类时，它需要读取并解析 Class 文件获取相关信息，再将信息存入到方法区。方法区会存储已被虚拟机加载的  **类信息、字段信息、方法信息、常量、静态变量、即时编译器编译后的代码缓存等数据** 。

#### 运行时常量池

用于存放编译期生成的各种字面量（Literal）和符号引用（Symbolic Reference），常量池会在类加载后存放到方法区的运行常量池中。

#### 字符串常量池

**字符串常量池** 是 JVM 为了提升性能和减少内存消耗针对字符串（String 类）专门开辟的一块区域，主要目的是为了避免字符串的重复创建。

JDK1.7 之前，字符串常量池存放在永久代。JDK1.7 字符串常量池和静态变量从永久代移动了 Java 堆中。

### JVM垃圾回收

https://pdai.tech/md/java/jvm/java-jvm-struct.html

在 JDK 7 版本及 JDK 7 版本之前，堆内存被通常分为下面三部分：

1. 新生代内存(Young Generation)
2. 老年代(Old Generation)
3. 永久代(Permanent Generation)

下图所示的 Eden 区、两个 Survivor 区 S0 和 S1 都属于新生代，中间一层属于老年代，最下面一层属于永久代。

![hotspot-heap-structure](https://javaguide.cn/assets/hotspot-heap-structure.41533631.png)

**JDK 8 版本之后 PermGen(永久) 已被 Metaspace(元空间) 取代，元空间使用的是直接内存** 。

大部分情况，对象都会首先在 Eden 区域分配。如果Eden区满了会触发Minor GC，如果对象在 Eden 出生并经过第一次 Minor GC 后仍然能够存活，并且能被 Survivor 容纳的话，将被移动到 Survivor 空间（s0 或者 s1）中，并将对象年龄设为 1(Eden 区->Survivor 区后对象的初始年龄变为 1)。如果Survive空间不足则直接进入老年代。

对象在 Survivor 中每熬过一次 MinorGC,年龄就增加 1 岁，当它的年龄增加到一定程度（默认为 15 岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 `-XX:MaxTenuringThreshold` 来设置。

大对象直接进入老年区，大对象就是需要大量连续内存空间的对象（比如：字符串、数组）。大对象直接进入老年代主要是为了避免为大对象分配内存时由于分配担保机制带来的复制而降低效率。

CG的两种方式：

部分收集 (Partial GC)：

* 新生代收集（Minor GC / Young GC）：只对新生代进行垃圾收集；
* 老年代收集（Major GC / Old GC）：只对老年代进行垃圾收集。需要注意的是 Major GC 在有的语境中也用于指代整堆收集；
* 混合收集（Mixed GC）：对整个新生代和部分老年代进行垃圾收集。

整堆收集 (Full GC)：收集整个 Java 堆和方法区。

GC触发机制：

1. 当新生代Eden区域满时触发Minor GC，此时如果Survive空间不足则有些对象会晋升至老年代；
2. 如果根据之前的统计数据发现平均晋升空间比目前老年代剩余空间大，则触发Full GC，Full GC会收集整个GC堆包括新生代

#### 死亡对象判断方法

- 引用计数法：每有一个引用计数+1，计数为0则表示不可能再被引用，但是无法解决循环引用问题；
- 可达性分析算法：这个算法的基本思想就是通过一系列的称为 **“GC Roots”** 的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到 GC Roots 没有任何引用链相连的话，则证明此对象是不可用的，需要被回收。

可以作为 GC Roots 的对象：

* 虚拟机栈(栈帧中的本地变量表)中引用的对象
* 本地方法栈(Native 方法)中引用的对象
* 方法区中类静态属性引用的对象
* 方法区中常量引用的对象
* 所有被同步锁持有的对象

引用类型总结：

- 强引用：绝对不会被回收。
- 软引用：内存空间不足时被回收。
- 弱引用：被垃圾回收器发现时被回收。
- 虚引用：任何时候都有可能被回收。

#### 垃圾回收算法

- 标记-清除法：先标记出不需要回收的对象，标记完成后统一回收未标记空间。效率较低，会产生大量不连续空间；
- 标记-复制法：将内存分为两块，每次使用一块，在一块使用完成后将存活对象复制到另一块中，再把使用堆空间一次性清理掉。
- 标记-整理法：将标记的对象向一端移动然后清理掉边界以外的内存区域。
- 分代收集算法：当前虚拟机的垃圾收集都采用分代收集算法，这种算法没有什么新的思想，只是根据对象存活周期的不同将内存分为几块。一般将 java 堆分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。**比如在新生代中，每次收集都会有大量对象死去，所以可以选择”标记-复制“算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。**

**延伸面试问题：** HotSpot 为什么要分为新生代和老年代？

根据上面的对分代收集算法的介绍回答。

#### 垃圾回收器

https://blog.csdn.net/weixin_45970271/article/details/123508686

https://blog.csdn.net/sermonlizhi/article/details/124867348

https://www.jianshu.com/p/f845b924d9dd

##### CMS

1. 初始标记： 暂停其他的所有线程（STW），记录下能通过 gc roots 直接引用的对象，只有一层遍历，速度很快。
2. 并发标记： 并发标记指的是从第1步中记录的 gc roots 直接引用的对象遍历到整个内存的对象的过程，这个过程耗时较长，但可以与用户线程并发运行。但因为用户线程也在运行，所有会导致已标记的对象状态发生改变。
3. 重新标记： 重新标记指修正在并发标记期间由于用户线程并行运行导致的对象引用状态发生变化的那一部分对象，这个阶段也会STW，但是这个阶段的停顿时间一般比初始标记要长，但是远比并发标记时间短。这里主要用到的三色标记法的增量更新做重新标记。
4. 并发清理： 开启线程，对未被标记的对象做清理，这个阶段如果有新增的对象都不会认为是垃圾对象，不做任何处理。
5. 并发重置： 重置这一轮GC过程的对象标记状态。
   ————————————————
   版权声明：本文为CSDN博主「肯定不吃番茄啊」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
   原文链接：https://blog.csdn.net/weixin_42274562/article/details/127679143

##### G1

1. 初始标记：需要暂定所有线程，即STW，并记录下GC Roots能直接引用的对象，速度很快。与CMS的初始标记一样
2. 并发标记：可以与应用线程一起工作，进行可达性分析，与CMS的并发标记一样
3. 最终标记：需要暂定所有线程(STW)，根据三色标记算法修复一些引用的状态，与CMS的重新标记是一样的
4. 筛选回收：筛选回收阶段会对各个Region的回收价值和成本进行排序，根据用户所期望的GC停顿STW时间(可以通过参数 -XX:MaxGCPauseMillis设置)来制定回收计划。比如此时有1000个Region都满了，但根据用户设置的STW时间，本次垃圾回收只能停顿200毫秒，那么通过之前的回收成本计算，200毫秒只能回收600个Region的内存空间，那么G1就会只回收这600个Region(Collection Set，要回收的集合)的内存空间，尽量把GC的停顿时间控制在用户指定的停顿时间内。在回收的时候，使用的是复制算法，将一个Region中的存活对象移动到另一个空的Regin中，然后将之前的Region内存空间清空，G1就不需要像CMS那样回收完内存后因为有很多脆片还要进行整理，采用复制算法几乎不会有内存碎片。

CMS在并发清理阶段，垃圾收集线程是可以与用户线程一起并发执行，但G1因为内部实现太复杂就没有实现并行回收，不过到了ZGC就实现了并发收集。
————————————————
版权声明：本文为CSDN博主「sermonlizhi」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/sermonlizhi/article/details/124867348

## Java设计模式

| 分类       | 包含                                                                                                                                               | 关注点                             |
| ---------- | -------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------- |
| 创建型模式 | 工厂模式、抽象工厂模式、单例模式、建造者模式、<br />原型模式                                                                                       | 关注于对象的创建，同时隐藏创建逻辑 |
| 结构型模式 | 适配器模式、过滤器模式、装饰模式、享元模式、<br />代理模式、外观模式、组合模式、桥接模式                                                           | 关注类和对象之间的组合             |
| 行为型模式 | 责任链模式、命令模式、中介者模式、观察者模式、<br />状态模式、策略模式、模板模式、空对象模式、<br />备忘录模式、迭代器模式、解释器模式、访问者模式 | 关注对象之间的通信                 |

### 单例模式

https://blog.csdn.net/weixin_44471490/article/details/108929289

用于在Java虚拟机中只存在一个实例的情况。

```java
public class Singleton {

//  private String singleton;

  private Singleton() {

  }

  private static Singleton singleton = null;

  //静态工厂方法，线程不安全
  public static Singleton getInstance1() {
    if (singleton == null) {
      singleton = new Singleton();
    }
    return singleton;
  }

  //加上synchroized
  public static synchronized Singleton getInstance2() {
    if (singleton == null) {
      singleton = new Singleton();
    }
    return singleton;
  }

  //双重检查锁定
  public static Singleton getInstance3() {
    if (singleton == null) {
      synchronized (Singleton.class) {
        singleton = new Singleton();
      }
    }
    return singleton;
  }

  //静态内部类
  private static class LazyHolder {
    private static final Singleton SINGLETON = new Singleton();
  }
  public static Singleton getInstance4() {
    return LazyHolder.SINGLETON;
  }

}

```

### 工厂模式

https://blog.csdn.net/a745233700/article/details/120253639

将创建对象的具体过程屏蔽隔离起来，达到更好的灵活性。

#### 简单工厂模式

客户端通过参数来获取对应类，不需要知道类名和具体创建过程，但是不符合开闭原则，新增产品时需要修改工厂代码。

#### 工厂方法模式

将工厂抽象化，定义一个创建对象接口，每增加新产品只需增加对应产品的工厂实现类，将对象的创建延迟到子类，这样符合开闭原则。在使用时通过具体产品的工厂即可创建。缺点在于每个产品需要对应一个工厂，使得系统中类的个数成倍增加。

#### 抽象工厂模式

抽象工厂模式主要用于创建相关对象的家族。当一个产品族中需要被设计在一起工作时，通过抽象工厂模式，能够保证客户端始终只使用同一个产品族中的对象；并且通过隔离具体类的生成，使得客户端不需要明确指定具体生成类；所有的具体工厂都实现了抽象工厂中定义的公共接口，因此只需要改变具体工厂的实例，就可以在某种程度上改变整个软件系统的行为。

    但该模式的缺点在于添加新的行为时比较麻烦，如果需要添加一个新产品族对象时，需要更改接口及其下所有子类，这必然会带来很大的麻烦。
————————————————
版权声明：本文为CSDN博主「张维鹏」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/a745233700/article/details/120253639

https://blog.csdn.net/weixin_45525272/article/details/126317048

# Netty

# Mybatis

# MySQL

## 主键与外键

- 主键用于唯一标识一个元组，不能重复， 不允许为空。一个表只能有一个主键。
- 外键用于和其他表建立联系用，外键是另一表的主键，可以重复，可以是空值，一个表可以有多个外键。

## 为什么不推荐外键与级联

* **增加了复杂性：** a. 每次做 DELETE 或者 UPDATE 都必须考虑外键约束，会导致开发的时候很痛苦, 测试数据极为不方便; b. 外键的主从关系是定的，假如那天需求有变化，数据库中的这个字段根本不需要和其他表有关联的话就会增加很多麻烦。
* **增加了额外工作** ： 数据库需要增加维护外键的工作，比如当我们做一些涉及外键字段的增，删，更新操作之后，需要触发相关操作去检查，保证数据的的一致性和正确性，这样会不得不消耗资源；（个人觉得这个不是不用外键的原因，因为即使你不使用外键，你在应用层面也还是要保证的。所以，我觉得这个影响可以忽略不计。）
* **对分库分表不友好** ：因为分库分表下外键是无法生效的。

## 什么是关系型数据库

就是一种建立在关系模型基础上的数据库，关系模型表明了数据库中所存储数据的联系（一对一、一对多、多对多）。

## 事务的四大特性

### 原子性

一个事务要么全部提交，要么失败全部回滚，不能只执行其中的一部分操作。

### 一致性

### 隔离性

#### 数据概念

- 脏读：事务B会读取到，事务A未提交（也可能是回滚前）的数据。
- 不可重复读：一个事务先后读取一条记录，而事务在两次读取之间该数据被其他事务修改，导致两次读取的数据不同，称为不可重复读。
- 幻读：事务A查询表中全部数据，而后事务B向表中新增数据，当事务A再次查询全部数据时会发现，第二次查询数据比第一次多，好像出现了幻觉，这就是幻读。

#### 隔离级别

- 读未提交：一个事务可以读取另一个未提交事务的数据。
- 读已提交：一个事务要等另一个事务提交后才可读取数据。
- 可重复读：事务开始读取数据（事务开始）时，会将所读取数据加锁，不再允许其他事务的修改操作。
- 序列化：事务的最高隔离级别，该级别下事务串行操作，效率低下一般不使用。

|          | 脏读 | 不可重复读 | 幻读 |
| -------- | ---- | ---------- | ---- |
| 读未提交 | Yes  | Yes        | Yes  |
| 读已提交 | No   | Yes        | Yes  |
| 可重复读 | No   | No         | Yes  |
| 序列化   | No   | No         | No   |

大多数数据库的隔离级别是读已提交，MySQL的InnoDB的默认隔离级别是可重复读。

### 持久性

一旦事务提交，则数据库中对应数据的状态会永久的保存到数据库中，一旦系统崩溃或宕机只要数据库能重新启动，则一定能将其恢复到事务成功结束的状态。

### MySQL存储引擎

默认为InnoDB，使用B+树结构，三层即可支持两千万条数据的存储，B+树的叶子节点用指针串联，方便全表检索。如果使用二叉树或红黑树，则会导致树过高影响检索效率。

### MVCC多版本并发控制

MVCC即（**Multi-Version Concurrency Control**）

https://zhuanlan.zhihu.com/p/421769708

## 索引

优点：

- 大大加快检索速度
- 通过创建唯一索引，可以保证数据库表中每一行数据的唯一性

缺点：

* 创建索引和维护索引需要耗费许多时间。当对表中的数据进行增删改的时候，如果数据有索引，那么索引也需要动态的修改，会降低 SQL 执行效率。
* 索引需要使用物理文件存储，也会耗费一定空间。
* 大多数情况下，索引比全表扫描要快。但是如果数据库数量不大，那么使用索引也不一定能带来很大提升。

### 索引的底层数据结构

#### Hash表

使用链地址法解决哈希冲突问题。但是Hash索引不支持顺序和范围查询，相较于B+树索引效率过低。

#### B树/B+树索引

* B 树的所有节点既存放键(key) 也存放 数据(data)，而 B+树只有叶子节点存放 key 和 data，其他内节点只存放 key。
* B 树的叶子节点都是独立的;B+树的叶子节点有一条引用链指向与它相邻的叶子节点。
* B 树的检索的过程相当于对范围内的每个节点的关键字做二分查找，可能还没有到达叶子节点，检索就结束了。而 B+树的检索效率就很稳定了，任何查找都是从根节点到叶子节点的过程，叶子节点的顺序检索很明显。

## 索引类型

### 主键索引

数据库表的主键列使用的就是主键索引，并且主键不能为null，且不能重复。

在MySQL的InnoDB表中，当没有显示指定表的主键的时候，InnoDB会先检查表中是否有唯一索引且不允许存在null值的字段，如果有则，该字段为默认的主键，否则InnoDB会默认创建一个6Byte的自增主键。

### 二级索引

二级索引又称为辅助索引，二级索引的叶子节点的数据是主键，也就是说，通过二级索引可以定位到主键的位置。

唯一索引、普通索引、前缀索引都属于二级索引。

* **唯一索引(Unique Key)** ：唯一索引也是一种约束。**唯一索引的属性列不能出现重复的数据，但是允许数据为 NULL，一张表允许创建多个唯一索引。** 建立唯一索引的目的大部分时候都是为了该属性列的数据的唯一性，而不是为了查询效率。
* **普通索引(Index)** ：**普通索引的唯一作用就是为了快速查询数据，一张表允许创建多个普通索引，并允许数据重复和 NULL。**
* **前缀索引(Prefix)** ：前缀索引只适用于字符串类型的数据。前缀索引是对文本的前几个字符创建索引，相比普通索引建立的数据更小， 因为只取前几个字符。
* **全文索引(Full Text)** ：全文索引主要是为了检索大文本数据中的关键字的信息，是目前搜索引擎数据库使用的一种技术。Mysql5.6 之前只有 MYISAM 引擎支持全文索引，5.6 之后 InnoDB 也支持了全文索引。

### 聚簇索引和非聚簇索引

#### 聚簇索引

聚簇索引是索引结构和数据一起存放的索引，并不是一种单独的索引类型，InnoDB中的索引就属于聚簇索引。

优点：

- 查询速度非常快，定位到了索引就相当于定位到数据，相比于非聚簇索引少了一次IO操作。
- 对于排序查找和范围查找优化，聚簇索引对主键的排序查找和范围查找速度非常快。

缺点：

- 依赖于有序的数据，因为B+树是多路平衡树，如果索引不是有序的话需要在插入的时候进行排序，如果数据是整型还好，否则类似于字符串或 UUID 这种又长又难比较的数据，插入或查找的速度肯定比较慢。
- 更新代价大，如果对索引列的数据进行修改时，那么对应的索引也会被修改，而聚集索引的叶子节点还存放着数据，所以更新代价很大，因为主键索引是聚集索引，所以主键一般不允许被修改。

#### 非聚簇索引

非聚簇索引即索引和主键分开存放的索引，并不是一种单独的索引类型，二级索引（辅助索引）就属于非聚簇索引。MySQL的MyISAM引擎不管是主键还是非主键，都是用的是非聚簇索引。

优点：

- 更新代价比聚簇索引小。

缺点：

- 依赖于有序的数据。
- 可能会二次查询，当索引查询到对应主键后可能还需要根据指针或主键再到主聚文件或表中查询。

### 覆盖索引和联合索引

- 覆盖索引：一个索引包含所有需要查询的字段，InnoDB中如果不是主键索引，最终还是要回表查询一次这样会比较慢，覆盖索引就是索引和要查询的字段是对应的不做回表操作。
- 联合索引：使用表中多个字段创建索引，也叫组合索引或联合索引。

最左前缀匹配原则：

联合索引中，MySQL会根据联合索引中的字段顺序，从左到右依次到查询条件中去匹配，直至全部字段匹配完成或遇到范围查询，如  **`>`** 、 **`<`** 、**`between`** 和 **`以%开头的like查询`** 等条件，才会停止匹配。所以在使用联合索引时，可以将区分度高的字段放在最左端，以便高效过滤数据。

### 索引字段建议

选择合适的字段创建索引：

- 不为NULL值的字段，建议使用0、1、true、false这样语意清晰的字段代替；
- 被频繁查询的字段；
- 被作为条件查询的字段：被作为WHERE条件查询的字段；
- 频繁需要排序的字段：索引本身就已经排序，这样可以利用索引的排序加快排序时间；
- 被频繁用于连接的字段：可能是外键列，外键列并不一定要建立外键，只是说该列涉及到表与表的关系。对于频繁被连接查询的字段，可以考虑建立索引，提高多表连接查询的效率。

其他建议：

- 被频繁修改的字段应慎重建立索引；
- 尽可能考虑联合索引而不是单列索引；
- 避免冗余索引；
- 考虑在字符串类型上使用前缀索引代替普通索引。

索引失效的情况：

- 使用 `SELECT *`进行查询；
- 创建了联合索引，但查询条件未遵守最左匹配原则；
- 在索引列上进行计算、函数、类型转换等；
- 以 `%`开头的LIKE查询比如 `LIKE '%abcd'`；
- 查询条件中使用or，且or的前后条件中有一个没有建立索引

# MongoDB

原文链接：https://javaguide.cn/database/mongodb/mongodb-questions-01.html

* **数据记录被存储为文档** ：MongoDB 中的记录就是一个 BSON 文档，它是由键值对组成的数据结构，类似于 JSON 对象，是 MongoDB 中的基本数据单元。
* **模式自由** ：集合的概念类似 MySQL 里的表，但它不需要定义任何模式，能够用更少的数据对象表现复杂的领域模型对象。
* **支持多种查询方式** ：MongoDB 查询 API 支持读写操作 (CRUD)以及数据聚合、文本搜索和地理空间查询。
* **支持 ACID 事务** ：NoSQL 数据库通常不支持事务，为了可扩展和高性能进行了权衡。不过，也有例外，MongoDB 就支持事务。与关系型数据库一样，MongoDB 事务同样具有 ACID 特性。MongoDB 单文档原生支持原子性，也具备事务的特性。MongoDB 4.0 加入了对多文档事务的支持，但只支持复制集部署模式下的事务，也就是说事务的作用域限制为一个副本集内。MongoDB 4.2 引入了分布式事务，增加了对分片集群上多文档事务的支持，并合并了对副本集上多文档事务的现有支持。
* **高效的二进制存储** ：存储在集合中的文档，是以键值对的形式存在的。键用于唯一标识一个文档，一般是 ObjectId 类型，值是以 BSON 形式存在的。BSON = Binary JSON， 是在 JSON 基础上加了一些类型及元数据描述的格式。
* **自带数据压缩功能** ：存储同样的数据所需的资源更少。
* **支持 mapreduce** ：通过分治的方式完成复杂的聚合任务。不过，从 MongoDB 5.0 开始，map-reduce 已经不被官方推荐使用了，替代方案是 [聚合管道open in new window](https://www.mongodb.com/docs/manual/core/aggregation-pipeline/)。聚合管道提供比 map-reduce 更好的性能和可用性。
* **支持多种类型的索引** ：MongoDB 支持多种类型的索引，包括单字段索引、复合索引、多键索引、哈希索引、文本索引、 地理位置索引等，每种类型的索引有不同的使用场合。
* **支持 failover** ：提供自动故障恢复的功能，主节点发生故障时，自动从从节点中选举出一个新的主节点，确保集群的正常使用，这对于客户端来说是无感知的。
* **支持分片集群** ：MongoDB 支持集群自动切分数据，让集群存储更多的数据，具备更强的性能。在数据插入和更新时，能够自动路由和存储。
* **支持存储大文件** ：MongoDB 的单文档存储空间要求不超过 16MB。对于超过 16MB 的大文件，MongoDB 提供了 GridFS 来进行存储，通过 GridFS，可以将大型数据进行分块处理，然后将这些切分后的小文档保存在数据库中。

### MongoDB聚合

将多个文档甚至多个集合汇总到一起计算分析，并返回计算后到结果，这个过程被称为聚合操作。

聚合操作可以：

- 将来自多个文档的值组合在一起；
- 对集合中的数据进行一系列运算；
- 分析数据随时间的变化。

MongoDB提供的的两种聚合方法：

- 聚合管道（Aggregation Pipline）：执行聚合操作的首选方法；
- 单一目的聚合方法（Single purpose aggregation methods）：也就是单一作用的聚合函数比如 `count()`、`distinct()`、`estimatedDocumentCount()`。

**常用阶段操作符** ：

| 操作符   | 简述                                                                                                 |
| -------- | ---------------------------------------------------------------------------------------------------- |
| $match   | 匹配操作符，用于对文档集合进行筛选                                                                   |
| $project | 投射操作符，用于重构每一个文档的字段，可以提取字段，重命名字段，甚至可以对原有字段进行操作后新增字段 |
| $sort    | 排序操作符，用于根据一个或多个字段对文档进行排序                                                     |
| $limit   | 限制操作符，用于限制返回文档的数量                                                                   |
| $skip    | 跳过操作符，用于跳过指定数量的文档                                                                   |
| $count   | 统计操作符，用于统计文档的数量                                                                       |
| $group   | 分组操作符，用于对文档集合进行分组                                                                   |
| $unwind  | 拆分操作符，用于将数组中的每一个值拆分为单独的文档                                                   |
| $lookup  | 连接操作符，用于连接同一个数据库中另一个集合，并获取指定的文档，类似于 populate                      |

更多操作符介绍详见官方文档：https://docs.mongodb.com/manual/reference/operator/aggregation/

---

著作权归所有
原文链接：https://javaguide.cn/database/mongodb/mongodb-questions-01.html

### MongoDB事务

MongoDB 单文档原生支持原子性，也具备事务的特性。当谈论 MongoDB 事务的时候，通常指的是 **多文档** 。MongoDB 4.0 加入了对多文档 ACID 事务的支持，但只支持复制集部署模式下的 ACID 事务，也就是说事务的作用域限制为一个副本集内。MongoDB 4.2 引入了 **分布式事务** ，增加了对分片集群上多文档事务的支持，并合并了对副本集上多文档事务的现有支持。

### MongoDB索引

**MongoDB 支持多种类型的索引，包括单字段索引、复合索引、多键索引、哈希索引、文本索引、 地理位置索引等，每种类型的索引有不同的使用场合。**

* **单字段索引：** 建立在单个字段上的索引，索引创建的排序顺序无所谓，MongoDB 可以头/尾开始遍历。
* **复合索引：** 建立在多个字段上的索引，也可以称之为组合索引、联合索引。
* **多键索引** ：MongoDB 的一个字段可能是数组，在对这种字段创建索引时，就是多键索引。MongoDB 会为数组的每个值创建索引。就是说你可以按照数组里面的值做条件来查询，这个时候依然会走索引。
* **哈希索引** ：按数据的哈希值索引，用在哈希分片集群上。
* **文本索引：** 支持对字符串内容的文本搜索查询。文本索引可以包含任何值为字符串或字符串元素数组的字段。一个集合只能有一个文本搜索索引，但该索引可以覆盖多个字段。MongoDB 虽然支持全文索引，但是性能低下，暂时不建议使用。
* **地理位置索引：** 基于经纬度的索引，适合 2D 和 3D 的位置查询。
* **唯一索引** ：确保索引字段不会存储重复值。如果集合已经存在了违反索引的唯一约束的文档，则后台创建唯一索引会失败。
* **TTL 索引** ：TTL 索引提供了一个过期机制，允许为每一个文档设置一个过期时间，当一个文档达到预设的过期时间之后就会被删除。

#### 复合索引

https://javaguide.cn/database/mongodb/mongodb-questions-02.html#mongodb-%E6%94%AF%E6%8C%81%E5%93%AA%E4%BA%9B%E7%B1%BB%E5%9E%8B%E7%9A%84%E7%B4%A2%E5%BC%95

在复合索引中，按照何种方式排序，决定了该索引在查询中是否能被应用到。

**MongoDB 的复合索引遵循左前缀原则** ：拥有多个键的索引，可以同时得到所有这些键的前缀组成的索引，但不包括除左前缀之外的其他子集。比如说，有一个类似 `{a: 1, b: 1, c: 1, ..., z: 1}` 这样的索引，那么实际上也等于有了 `{a: 1}`、`{a: 1, b: 1}`、`{a: 1, b: 1, c: 1}` 等一系列索引，但是不会有 `{b: 1}` 这样的非左前缀的索引。

#### TTL索引

TTL 索引提供了一个过期机制，允许为每一个文档设置一个过期时间 `expireAfterSeconds` ，当一个文档达到预设的过期时间之后就会被删除。TTL 索引除了有 `expireAfterSeconds` 属性外，和普通索引一样。

数据过期对于某些类型的信息很有用，比如机器生成的事件数据、日志和会话信息，这些信息只需要在数据库中保存有限的时间。

# Redis

## Redis数据类型（五种）

## Redis为什么快

- Redis基于内存，访问速度是磁盘的上千倍；
- Redis基于Reactor模式开发设计了一套高效的事件处理模型，主要是单线程事件循环和IO多路复用；
- Redis内置了多种优化后的数据结构实现，性能非常高。

## Redis做缓存的优势

- 高性能：如果是高频数据且不会频繁改变的话就可以将该数据放进缓存中，操作缓存就是操作内存，所以速度非常快。
- 高并发：一般例如MySQL这类的数据库QPS大概都在1w左右，但是使用Redis后很容易达到10w，甚至最高能达到30w。直接操作缓存能够承受的数据库请求数量是远远大于直接访问数据库的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。进而，我们也就提高了系统整体的并发。

## Redis除了做缓存还能做什么

* **分布式锁** ： 通过 Redis 来做分布式锁是一种比较常见的方式。通常情况下，我们都是基于 Redisson 来实现分布式锁。关于 Redis 实现分布式锁的详细介绍，可以看我写的这篇文章：[分布式锁详解open in new window](https://javaguide.cn/distributed-system/distributed-lock.html) 。https://zhuanlan.zhihu.com/p/477526114 & https://blog.csdn.net/weixin_40918067/article/details/116561409
* **限流** ：一般是通过 Redis + Lua 脚本的方式来实现限流。相关阅读：[《我司用了 6 年的 Redis 分布式限流器，可以说是非常厉害了！》open in new window](https://mp.weixin.qq.com/s/kyFAWH3mVNJvurQDt4vchA)。
* **消息队列** ：Redis 自带的 list 数据结构可以作为一个简单的队列使用。Redis 5.0 中增加的 Stream 类型的数据结构更加适合用来做消息队列。它比较类似于 Kafka，有主题和消费组的概念，支持消息持久化以及 ACK 机制。
* **复杂业务场景** ：通过 Redis 以及 Redis 扩展（比如 Redisson）提供的数据结构，我们可以很方便地完成很多复杂的业务场景比如通过 bitmap 统计活跃用户、通过 sorted set 维护排行榜。

## String的底层实现

Redis 是基于 C 语言编写的，但 Redis 的 String 类型的底层实现并不是 C 语言中的字符串（即以空字符 `\0` 结尾的字符数组），而是自己编写了 [SDSopen in new window](https://github.com/antirez/sds)（Simple Dynamic String，简单动态字符串） 来作为底层实现。

SDS 最早是 Redis 作者为日常 C 语言开发而设计的 C 字符串，后来被应用到了 Redis 上，并经过了大量的修改完善以适合高性能操作。

## Redis单线程模型

Reactor模型：https://blog.csdn.net/u013277209/article/details/126200112

## Redis持久化机制

### RDB持久化

通过创建快照来获取存储在内存里面的数据在某个时间点上的副本。Redis创建快照后可以对快照进行备份，可以将快照复制到其他服务器上从而创建具有相同数据的副本（Rredis主从结构，主要用来提高Redis性能）。还可以将快照存储在本地以便重启服务器时使用。

快照持久化是Redis默认的持久化方案。

### AOF持久化

与快照持久化相比，AOF持久化的实时性更好，已经成为主流的持久化方案。通过开启 `appendonly yes`后Redis每执行一条会更改Redis数据的命令Redis就会将该命令写到内存缓存 `server.aof_buf`中，然后再根据 `appendfsync`配置来决定何时将其同步到硬盘中的AOF文件。

在 Redis 的配置文件中存在三种不同的 AOF 持久化方式，它们分别是：

```bash
appendfsync always    #每次有数据修改发生时都会写入AOF文件,这样会严重降低Redis的速度
appendfsync everysec  #每秒钟同步一次，显式地将多个写命令同步到硬盘
appendfsync no        #让操作系统决定何时进行同步
```

为了兼顾数据和写入性能，用户可以考虑 `appendfsync everysec` 选项 ，让 Redis 每秒同步一次 AOF 文件，Redis 性能几乎没受到任何影响。而且这样即使出现系统崩溃，用户最多只会丢失一秒之内产生的数据。当硬盘忙于执行写入操作的时候，Redis 还会优雅的放慢自己的速度以便适应硬盘的最大写入速度。

## Redis事务

Redis 可以通过 **`MULTI`，`EXEC`，`DISCARD` 和 `WATCH`** 等命令来实现事务(transaction)功能。

```bash
> MULTI
OK
> SET PROJECT "JavaGuide"
QUEUED
> GET PROJECT
QUEUED
> EXEC
1) OK
2) "JavaGuide"
```

[`MULTI`](https://redis.io/commands/multi)命令后可以输入多个命令，Redis 不会立即执行这些命令，而是将它们放到队列，当调用了 [`EXEC`](https://redis.io/commands/exec)命令后，再执行所有的命令。

Redis不支持回滚，所以Redis是不满足原子性的也不满足持久性。

## Redis生产问题

### 缓存穿透

大量的key是不合理的，既不存在于Redis也不存在数据库，导致请求直接到数据库上，没有经过缓存，给数据库造成巨大压力。

解决办法：

- 最好的解决办法是做好参数校验，不合理的请求直接返回错误信息。
- 布隆过滤器：通过哈希的方式检查请求的key是否存在于Redis中。

### 缓存击穿

查询频率较高的热点key没有存在Redis中（或是恰好过期），导致大量请求直接打到数据库上造成巨大压力。

解决办法：

* 设置热点数据永不过期或者过期时间比较长。
* 针对热点数据提前预热，将其存入缓存中并设置合理的过期时间比如秒杀场景下的数据在秒杀结束之前不过期。
* 请求数据库写数据到缓存之前，先获取互斥锁，保证只有一个请求会落到数据库上，减少数据库的压力。

### 缓存雪崩

大量key集体过期导致请求直接打到数据库。

解决方法：

**针对 Redis 服务不可用的情况：**

1. 采用 Redis 集群，避免单机出现问题整个缓存服务都没办法使用。
2. 限流，避免同时处理大量的请求。

**针对热点缓存失效的情况：**

1. 设置不同的失效时间比如随机设置缓存的失效时间。
2. 缓存永不失效（不太推荐，实用性太差）。
3. 设置二级缓存。

## 如何保证缓存与数据库一致性

先更新数据库再删除缓存。

细说的话可以扯很多，但是我觉得其实没太大必要（小声 BB：很多解决方案我也没太弄明白）。我个人觉得引入缓存之后，如果为了短时间的不一致性问题，选择让系统设计变得更加复杂的话，完全没必要。

下面单独对 **Cache Aside Pattern（旁路缓存模式）** 来聊聊。

Cache Aside Pattern 中遇到写请求是这样的：更新 DB，然后直接删除 cache 。

如果更新数据库成功，而删除缓存这一步失败的情况的话，简单说两个解决方案：

1. **缓存失效时间变短（不推荐，治标不治本）** ：我们让缓存数据的过期时间变短，这样的话缓存就会从数据库中加载数据。另外，这种解决办法对于先操作缓存后操作数据库的场景不适用。
2. **增加 cache 更新重试机制（常用）** ： 如果 cache 服务当前不可用导致缓存删除失败的话，我们就隔一段时间进行重试，重试次数可以自己定。如果多次重试还是失败的话，我们可以把当前更新失败的 key 存入队列中，等缓存服务可用之后，再将缓存中对应的 key 删除即可。

相关文章推荐：[缓存和数据库一致性问题，看这篇就够了 - 水滴与银弹open in new window](https://mp.weixin.qq.com/s?__biz=MzIyOTYxNDI5OA==&mid=2247487312&idx=1&sn=fa19566f5729d6598155b5c676eee62d&chksm=e8beb8e5dfc931f3e35655da9da0b61c79f2843101c130cf38996446975014f958a6481aacf1&scene=178&cur_album_id=1699766580538032128#rd)

## Redis过期策略

定期删除+惰性删除：定期删除是每隔100ms在设置了过期时间的key里面随机选择一些，如果过期则删除。惰性删除指当获取某个key的时候如果这个key已经过期则直接删除没有返回。

内存淘汰机制：常用的策略是删除最近最少使用的key（LRU）

redis 内存淘汰机制有以下几个：

- noeviction: 当内存不足以容纳新写入数据时，新写入操作会报错，这个一般没人用吧，实在是太恶心了。
- allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的）。随机取出若干个key，按照时间排序后淘汰最不常用的。
- allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个 key，这个一般没人用吧，为啥要随机，肯定是把最近最少使用的 key 给干掉啊。
- volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的 key（这个一般不太合适）。
- volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个 key。
- volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的 key 优先移除。
  ————————————————
  版权声明：本文为CSDN博主「Go Big Or Go Home」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
  原文链接：https://blog.csdn.net/u011663149/article/details/95229935

**所以不要使用Redis过期监听来实现定时任务！**

## Redis高可用的三种实现方式

https://blog.csdn.net/weixin_44183721/article/details/126195582

高可用(High Availability,即HA)，指的是通过尽量缩短日常维护操作和突发的系统崩溃所导致的停机时间，以提高系统和应用的可用性。

### 主从模式

部署多台Redis节点，只有一台是主节点（master），其他都是从节点（salve），只有主节点提供事务性操作，其他从节点提供读操作所有salve节点的数据都是从master节点同步过来的。

主从模式实现了读写分离，减轻了master节点的读压力，但是当master节点宕机时无法选择一个salve节点作为新的master节点无法保证高可用，而且没有解决master节点的写压力。

### 哨兵模式

在主从模式中，一旦master节点宕机需要找一个salve节点来作为新的master节点。谁来确定宕机，以及选择哪一个节点作为新的master节点这些问题都没有解决。哨兵模式对每个节点进行监控当出现故障时通过投票机制选择新的master节点并将所有salve节点连接到master节点。

哨兵的上个作用：

- 监控：不断检查各个节点的运行状态、是否存活；
- 通知：当某个节点出现异常状况时，通过API向管理员或者其他应用程序发出通知；
- 自动故障转移：断开master和salve之间的连接，选取新的master节点将其他salve连接到新的master，并告知客户端新的节点地址。

哨兵模式的优点是保证了高可用，能够监控各个节点的运行状态，进行自动故障转移

但是缺点是：

- 中心化集群的实现方式，基于主从模式，切换节点时会丢失数据；
- 节点保存的是全量的数据，没有实现真正的分布式数据量过大时，主从同步严重影响master的性能；
- 写操作都集中在master节点依然没有解决master写数据的压力。

### 集群模式

哨兵模式已经基本实现了高可用，但是每个节点存储的内容都相同浪费了内存空间，而且没有解决master节点写的压力，为了解决这些问题，就有了集群模式，实现分布式存储，每个节点存储不同的内容，通过数据分片将数据放到不同的master节点上，为每个master节点配备salve节点进行数据的同步和读取，各个master-salve节点之间通过建立TCP连接，使用gossip协议来进行集群信息传播。

故障判断方法：每个节点会定期向其他节点发送ping命令，通过有没有收到回复来判断其他节点是否下线，如果A节点发现目标节点疑似下线，那么会向集群中的其他节点来散布消息，其他节点会向目标节点发送命令，如果半数以上节点都认为目标节点下线则该节点会被标记为下线。

集群模式的优点是：

- 无中心节点，部署简单，各个节点彼此互联，内部使用二进制协议来优化传输速度和带宽；
- 可拓展性，可以拓展master节点释放单个master节点的写压力，节点可动态删除和增加；
- 能够实现自动故障转移，节点之间通过gossip协议来交换信息，用投票机制完成salve到master的角色转换；

# RabbitMQ

RabbitMQ 是采用 Erlang 语言实现 AMQP(Advanced Message Queuing Protocol，高级消息队列协议）的消息中间件，它最初起源于金融系统，用于在分布式系统中存储转发消息。

## 核心概念

### 生产者（Productor）和消费者（Comsumer）

消息一般由 2 部分组成： **消息头** （或者说是标签 Label）和  **消息体** 。消息体也可以称为 payLoad ,消息体是不透明的，而消息头则由一系列的可选属性组成，这些属性包括 routing-key（路由键）、priority（相对于其他消息的优先权）、delivery-mode（指出该消息可能需要持久性存储）等。生产者把消息交由 RabbitMQ 后，RabbitMQ 会根据消息头把消息发送给感兴趣的 Consumer(消费者)。

### Exchange（交换器）

消息并不是直接被投递到Queue中，中间还必须经过交换器这一层，**Exchange(交换器)** 用来接收生产者发送的消息并将这些消息路由给服务器中的队列中，如果路由不到，或许会返回给 **Producer(生产者)** ，或许会被直接丢弃掉。

生产者将消息发给交换器的时候，一般会指定一个  **RoutingKey(路由键)** ，用来指定这个消息的路由规则，而这个  **RoutingKey 需要与交换器类型和绑定键(BindingKey)联合使用才能最终生效** 。

RabbitMQ 中通过 **Binding(绑定)** 将 **Exchange(交换器)** 与 **Queue(消息队列)** 关联起来，在绑定的时候一般会指定一个 **BindingKey(绑定建)** ,这样 RabbitMQ 就知道如何正确将消息路由到队列了,如下图所示。一个绑定就是基于路由键将交换器和消息队列连接起来的路由规则，所以可以将交换器理解成一个由绑定构成的路由表。Exchange 和 Queue 的绑定可以是多对多的关系。

生产者将消息发送给交换器时，需要一个RoutingKey,当 BindingKey 和 RoutingKey 相匹配时，消息会被路由到对应的队列中。在绑定多个队列到同一个交换器的时候，这些绑定允许使用相同的 BindingKey。BindingKey 并不是在所有的情况下都生效，它依赖于交换器类型，比如fanout类型的交换器就会无视，而是将消息路由到所有绑定到该交换器的队列中。

#### 交换器类型

- fanout：fanout 类型的Exchange路由规则非常简单，它会把所有发送到该Exchange的消息路由到所有与它绑定的Queue中，不需要做任何判断操作，所以 fanout 类型是所有的交换机类型里面速度最快的。fanout 类型常用来广播消息。
- direct：direct 类型的Exchange路由规则也很简单，它会把消息路由到那些 Bindingkey 与 RoutingKey 完全匹配的 Queue 中。
- topic：topic类型的交换器在匹配规则上进行了扩展，它与 direct 类型的交换器相似，也是将消息路由到 BindingKey 和 RoutingKey 相匹配的队列中，但这里的匹配规则有些不同，使用“*"匹配一个单词用“#"匹配多个单词。
- headers（不推荐）：headers 类型的交换器不依赖于路由键的匹配规则来路由消息，而是根据发送的消息内容中的 headers 属性进行匹配。在绑定队列和交换器时指定一组键值对，当发送消息到交换器时，RabbitMQ会获取到该消息的 headers（也是一个键值对的形式)，对比其中的键值对是否完全匹配队列和交换器绑定时指定的键值对，如果完全匹配则消息会路由到该队列，否则不会路由到该队列。headers 类型的交换器性能会很差，而且也不实用，基本上不会看到它的存在。

## AMQP三大组件

* **交换器 (Exchange)** ：消息代理服务器中用于把消息路由到队列的组件。
* **队列 (Queue)** ：用来存储消息的数据结构，位于硬盘或内存中。
* **绑定 (Binding)** ：一套规则，告知交换器消息应该将消息投递给哪个队列。

## 死信队列

DLX，全称为 `Dead-Letter-Exchange`，死信交换器，死信邮箱。当消息在一个队列中变成死信 (`dead message`) 之后，它能被重新被发送到另一个交换器中，这个交换器就是 DLX，绑定 DLX 的队列就称之为死信队列。

 **导致的死信的几种原因** ：

* 消息被拒（`Basic.Reject /Basic.Nack`) 且 `requeue = false`。
* 消息 TTL 过期。
* 队列满了，无法再添加。

## 延迟队列

RabbitMQ本身是没有延迟队列的，要实现延迟消息，一般有两种方式：

1. 通过RabbitMQ本身队列的特性来实现，需要使用RabbitMQ的死信交换机（Exchange）和消息的存活时间TTL（Time To Live）。
2. 在RabbitMQ 3.5.7及以上的版本提供了一个插件（rabbitmq-delayed-message-exchange）来实现延迟队列功能。同时，插件依赖Erlang/OPT 18.0及以上。

也就是说，AMQP 协议以及RabbitMQ本身没有直接支持延迟队列的功能，但是可以通过TTL和DLX模拟出延迟队列的功能。但是不建议使用死信队列实现延迟队列，因为如果死信队列中已经有一条过期消息新的过期消息的投递会出现问题。

PS：经过我自己的实践测试，延迟队列插件延迟时间会有误差，多数在300毫秒左右。

## 优先级队列

RabbitMQ 自 V3.5.0 有优先级队列实现，优先级高的队列会先被消费。

可以通过 `x-max-priority`参数来实现优先级队列。不过，当消费速度大于生产速度且 Broker 没有堆积的情况下，优先级显得没有意义。

## 如何保证消息的可靠性

https://mp.weixin.qq.com/s?__biz=MzU2MDY0NDQwNQ==&mid=2247484081&idx=1&sn=13e0df37f96bd1ab952c15b4397dec9b&chksm=fc05aaebcb7223fd1cce327cb2322f16f908f50d5bb14d11128a653cf8548e126ac28990a2a7&scene=27

### 保证producer到broker的可靠性

#### 事务模式（Transaction）

在Transaction模式中，producer只有收到了broker返回的Commit-Ok命令后才能提交成功，若在commit执行之前，RabbitMQ发生故障抛出异常，producer可以将其捕获，然后通过Channel对象的txRollback()方法回滚事务，同时可以重发该消息。

但是Transaction模式是阻塞的会大幅降低性能，不推荐使用。

#### confirm模式（推荐）

confirm异步确认机制：

发送端发送消息后在等待确认的过程中可以发送下一条消息，每条消息都会分配一条唯一的ID（从1开始计数），这条消息被匹配到Queue队列后RabbitMQ会发送一个确认ACK给producer（如果是持久化消息将会在消息写入磁盘后发出），确认消息包含了消息的唯一ID，这样producer就知道消息已经成功到达队列。如果消息丢失或接收失败也会发送一条NACK给producer，这样producer就可以针对这条消息做相应处理。

confirm机制有的三种方式。

##### 单条确认方式

单条确认模式中，每发送一条消息后，通过调用Channel对象的waitForConfirms()方法等待RabbitMQ端确认，这种方式实际上是一种同步等待的方式，只有当一条消息被确认之后，才能发送下一条消息，所以，实际使用中不推荐这种方式。

##### 批量确认方式

批量确认方式与单条确认方式使用方法类似，只是将确认的步骤放到了最后，可以一次性发送多条消息，最后统一确认，waitForConfirmsOrDie()方法会等最后一条消息被确认或者得到nack时才会结束，这种方式虽然可以做到多条消息并行发送，不用互相等待，但最后确认的时候还是通过同步等待的方式完成的，所以也会造成程序的阻塞，并且当有任意一条消息未确认就会抛出异常，实际使用中不推荐这种方式。

##### 异步确认方式（推荐）

异步确认方式的实现原理是在将Channel设置为Confirm模式后，给该Channel添加一个监听ConfirmListener，ConfirmListener中定义了两个方法，一个是handleAck，用来处理RabbitMQ的ack确认消息，一个是handleNack，用来处理RabbitMQ的nack未确认消息，这两个方法会在RabbitMQ完成消息确认和发生故障导致消息丢失时回调，producer接收到回调时可以执行对应的回调处理。异步确认的方式效率很高，多条消息既可以同时发送，不需要互相等待，又不用同步等待确认结果，只需异步监听确认结果即可，所以，实际使用中推荐使用这种方式。

### 保证exchange路由消息到Queue的可靠性

#### ReturnListener

ReturnListener是一个监听器，作用于Channel信道上，当producer发送一条消息给RabbitMQ后，如果由于Routing key不存在导致消息不可成功到达Queue队列，RabbitMQ就会将这条消息发送回producer的ReturnListener，在ReturnListener的handleReturn方法中，producer可以针对退回的消息做处理。要使用ReturnListener，在发送消息时要注意，在basicPublish的方法中有一个mandatory的入参，只有将该参数值设置为true才可以正常使用ReturnListener，否则，当Routing key不存在时，消息会被自动丢弃。

#### 备胎Exchange交换机

除了使用ReturnListener，我们还可以使用备胎交换机的方式来解决Routing key不存在导致消息不可达的问题。所谓备胎交换机，是指当producer发送消息的Routing key不存在导致消息不可达时，自动将这条消息转发到另一个提前指定好的交换机上，这台交换机就是备胎交换机。备胎交换机也有自己绑定的Queue队列，当备胎交换机接到消息后，会将消息路由到自己匹配的Queue队列中，然后由订阅了这些Queue队列的消费者消费。如果要使用备胎交换机，也要在发送消息时，将mandatory参数值设置为true，否则，消息就会由于不可达而被RabbitMQ自动丢弃。

### 保证Queue消息存储的可靠性

设置消息和队列的持久化，将消息和队列信息保存到RabbitMQ的磁盘中，这样RabbitMQ重启时就可以从磁盘将消息和队列恢复，但是RabbitMQ接收到持久化消息后并不会立即写入磁盘，而是有一个缓冲buffer，buffer满了或者每25ms才会写入磁盘一次，这个问题可以通过搭建RabbitMQ镜像集群来解决。

此外，交换机也可以持久化，不过交换机是否持久化对消息的可靠性并没有什么影响，只是非持久化的交换机在RabbitMQ重启之后也会消失，那么producer向该交换机发送消息时就可能会有问题，所以，一般情况下，建议也将交换机持久化。

### 保证consumer消费消息的可靠性

consumer消费消息时，有一个ack机制，即向RabbitMQ发送一条ack指令，表示消息已经被成功消费，RabbitMQ收到ack指令后，会将消息从本地删除。默认情况下，consumer消费消息是自动ack机制，即消息只要到达consumer，就会向RabbitMQ发送ack，不管consumer是否消费成功。所以，为了保证producer与consumer数据的一致性，我们要使用手动ack的方式确认消息消费成功，即在消息消费完成后，通过代码显式调用发送ack。

consumer向RabbitMQ发送ack时有三种形式：

（1）reject：表示拒收消息。发送拒收消息时，需要设置一个 requeue 的参数，表示拒收之后，这条消息是否重新回到RabbitMQ的Queue之后，设置为true表示是，false表示否（消息会被删除）。若 requeue 设置为 true，那么消息回归原Queue之后，会被消费者重新消费，这样就会出现死循环，消费->拒绝->回Queue->消费->拒绝->回Queue......所以，一般设置为false。如果设置为true，那么最好限定消费次数，比如同一条消息消费5次之后就直接丢掉。

（2）nack：一般consumer消费消息出现异常时，需要发送nack给MQ，MQ接收到nack指令后，会根据发送nack时设置的requeue参数值来判断是否删除消息，如果requeue为true，那么消息会重新放入Queue队列中，如果requeue为false，消息就会被直接删掉。当requeue设置为true时，为了防止死循环性质的消费，最好限定消费次数，比如同一条消息消费5次之后就直接丢掉。

（3）ack：当consumer成功把消息消费掉后，需要发送ack给MQ，MQ接收到ack指令后，就会把消费成功的消息直接删掉。

## Shiro

## 微服务主要看设计理念、RPC框架、DDD模型、服务治理

https://blog.csdn.net/weixin_45203607/article/details/121886232
